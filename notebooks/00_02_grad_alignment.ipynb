{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e00976d-c767-4571-9a41-72111dd2101a",
   "metadata": {},
   "source": [
    "# Base Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8bc917d7-97be-4b85-af0d-16941f90e68a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install torch --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22a97802-3ec9-4a08-960a-9a71f1bbb844",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://wandb.ai/kilianovski/misha-iml/runs/kn69jraw\n",
    "\n",
    "\n",
    "checkpoint_path = '../models/transformers/pretrained_1L_dmodel=1024_attnonly=False20240718_200143.pt'\n",
    "checkpoint_path = '../models/transformers/grokking_prod_120_1_0.1_attnonly_False20240712_133838.pt'\n",
    "\n",
    "\n",
    "transformer_config = dict(\n",
    "    d_vocab=512,\n",
    "    n_layers=1,\n",
    "    d_model=1024,\n",
    "    d_head=128,\n",
    "    n_heads=4,\n",
    "    d_mlp=256,\n",
    "    n_ctx=5,\n",
    "    act_fn=\"relu\",  # gelu?\n",
    "    normalization_type='LN',\n",
    "    attn_only=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "416f5aa5-6d10-4c37-984e-93aa741c94ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from argparse import Namespace\n",
    "from dataclasses import dataclass, asdict\n",
    "seed = 2\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class TrainParams:\n",
    "    n_steps: int = int(1e8)\n",
    "    batch_size: int = 128\n",
    "    lr: float = 1e-4\n",
    "    wd: float = 1e-1\n",
    "    betas: tuple = (0.9, 0.98)\n",
    "    max_grad_norm: float = 1.0\n",
    "    num_epochs_X1: int = 500\n",
    "    num_epochs_X2: int = 500\n",
    "    prop_orig: float = 0.25\n",
    "    orig_held_out_frac: float = 0.01\n",
    "    swap_defs: bool = False # whether to swap the order of the defs\n",
    "    val_questions: int = 9\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8993d4e0-0462-4813-a5da-0a62311f0ec0",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8dc9b4b1-e546-48cc-aa75-2e4ad3747e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0031c9f1-ad7a-4f2f-bb0d-3281a5719fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data import create_datasets, seed_all, DataParams, Tokens, OOCL_Dataset, make_tbl_mask, create_orig_data, yield_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "23eda486-1d7d-40df-b059-39e83728297a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import torch\n",
    "from dataclasses import dataclass, asdict\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "from tqdm.auto import tqdm\n",
    "from pathlib import Path\n",
    "import itertools\n",
    "import sys\n",
    "import random\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import random_split, TensorDataset, DataLoader, Dataset\n",
    "import argparse\n",
    "from transformer_lens import HookedTransformer, HookedTransformerConfig\n",
    "import wandb\n",
    "from dotenv import load_dotenv\n",
    "from sympy import factorint\n",
    "from itertools import product\n",
    "from math import prod\n",
    "\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9c28bea9-8752-4d61-81b0-3a7257e4526d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_device():\n",
    "    #return 'cpu'\n",
    "    if torch.cuda.is_available():\n",
    "        return \"cuda\"\n",
    "    # elif torch.backends.mps.is_available():\n",
    "    #     return \"mps\"\n",
    "    else:\n",
    "        return \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9d13fe28-229b-4f95-b252-0bb51acf81fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def loss_fn(logits, tokens):\n",
    "\n",
    "    # check whether question or def and compute loss appropriately\n",
    "    # logit shape: [batch, pos, vocab]\n",
    "    # token shape: [batch, pos]\n",
    "\n",
    "    mask = (tokens[:, 3] == 2*DataParams.mod + Tokens.padding)\n",
    "\n",
    "    def_logits = logits[mask]\n",
    "    def_tokens = tokens[mask].long()\n",
    "\n",
    "    q_logits = logits[~mask]\n",
    "    q_tokens = tokens[~mask].long()\n",
    "\n",
    "    def_logits = def_logits[:, 1].unsqueeze(1)\n",
    "    def_tokens = def_tokens[:, 2].unsqueeze(1)\n",
    "    def_log_probs = def_logits.log_softmax(-1)\n",
    "    def_correct_log_probs = def_log_probs.gather(-1, def_tokens[..., None])[..., 0]\n",
    "    \n",
    "    q_logits = q_logits[:, 2].unsqueeze(1)\n",
    "    q_tokens = q_tokens[:, 3].unsqueeze(1)\n",
    "    q_log_probs = q_logits.log_softmax(-1)\n",
    "    q_correct_log_probs = q_log_probs.gather(-1, q_tokens[..., None])[..., 0]\n",
    "\n",
    "    return -(def_correct_log_probs.sum() + q_correct_log_probs.sum())/(def_correct_log_probs.shape[0] + q_correct_log_probs.shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "779d99c2-a67b-4666-9240-5fef019e4b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, val_loader, device):\n",
    "\n",
    "    correct = 0\n",
    "    loss = 0.\n",
    "    total = 0\n",
    "    batches = 0\n",
    "\n",
    "    for batch in val_loader:\n",
    "        inputs = batch[0].to(device)\n",
    "\n",
    "        labels = inputs[:, -1]\n",
    "\n",
    "        with torch.no_grad():\n",
    "            output = model(inputs)\n",
    "            loss += loss_fn(output, inputs).item()\n",
    "            correct += (torch.argmax(output[:, -2, :], dim=1) == labels).sum()\n",
    "\n",
    "        total += inputs.shape[0]\n",
    "        batches += 1\n",
    "\n",
    "    acc = correct / total\n",
    "    loss = loss/batches\n",
    "    return acc, loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab1de72-8943-4eb6-bfd5-d5f53991834d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0bae8695-44b4-4259-815e-7de8c7a2f818",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2f336bca-fa82-477f-812a-d076701bbefc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# int_by_set = {\n",
    "#     'DtQ1': [57, 103, 99, 3, 111, 59, 73, 22, 30, 25, 47, 69, 23, 67, 75, 16, 85, 29, 2, 76, 8, 107, 43, 84, 98, 44, 46, 115, 80, 37], \n",
    "#     'DfQ2': [50, 72, 118, 20, 93, 10, 52, 14, 83, 6, 28, 15, 34, 48, 114, 104, 88, 13, 91, 54, 112, 58, 102, 95, 21, 24, 19, 94, 35, 109], \n",
    "#     'Dt3': [4, 81, 82, 41, 31, 86, 63, 0, 110, 11, 1, 92, 7, 116, 66, 56, 119, 70, 26, 78, 40, 55, 105, 89, 71, 60, 42, 87, 9, 117], \n",
    "#     'Df4': [39, 18, 77, 90, 68, 32, 79, 12, 96, 101, 36, 17, 64, 27, 74, 45, 61, 38, 106, 100, 51, 62, 65, 33, 5, 53, 113, 97, 49, 108]\n",
    "# }\n",
    "\n",
    "\n",
    "# int_by_set = {\n",
    "#     'DtQ1': [119, 81, 20, 90, 68, 41, 4, 79, 38, 10, 14, 95, 22, 78, 114, 71, 73, 52, 94, 9, 82, 116, 96, 93, 39, 36, 105, 50, 16, 33], \n",
    "#     'DfQ2': [5, 30, 19, 59, 74, 24, 104, 21, 18, 51, 42, 61, 65, 84, 64, 35, 113, 11, 66, 80, 112, 7, 31, 98, 43, 6, 25, 45, 117, 47], \n",
    "#     'Dt3': [99, 46, 88, 23, 103, 53, 86, 37, 58, 76, 118, 44, 91, 70, 111, 56, 28, 67, 85, 54, 27, 106, 1, 69, 107, 87, 2, 101, 40, 13], \n",
    "#     'Df4': [75, 29, 92, 34, 109, 89, 0, 110, 77, 55, 49, 3, 62, 12, 26, 100, 48, 83, 60, 57, 115, 63, 15, 32, 8, 97, 102, 108, 72, 17]\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "627d8130-cc5a-4210-bb20-84fb24cd20c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from prettytable import PrettyTable\n",
    "except:\n",
    "    ! pip install -q prettytable\n",
    "    from prettytable import PrettyTable\n",
    "\n",
    "def count_parameters(model):\n",
    "    from prettytable import PrettyTable\n",
    "\n",
    "    table = PrettyTable([\"Modules\", \"Parameters\"])\n",
    "    total_params = 0\n",
    "    for name, parameter in model.named_parameters():\n",
    "        if not parameter.requires_grad: continue\n",
    "        params = parameter.numel()\n",
    "        table.add_row([name, params])\n",
    "        total_params+=params\n",
    "    print(table)\n",
    "    print(f\"Total Trainable Params: {total_params}\")\n",
    "    return total_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "232aa58b-38e8-4dcf-9252-0bb6c0a84a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# noisy_labels = {119+n for n in int_by_set['DfQ2']}\n",
    "\n",
    "# def randomize_noisy_labels(tokens):\n",
    "#     noisy_label_mask = torch.tensor(list(map(lambda x: any(int(l) in noisy_labels for l in x) , tokens[:, :2])))\n",
    "#     noisy_label_mask = noisy_label_mask & (tokens[:, 0] != 242)\n",
    "#     tokens[noisy_label_mask][:, -1] = torch.randint(0, 120*2, size=(len(tokens[noisy_label_mask]),))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "462010da-d6dd-4244-85c8-7709d5f0aae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_iml(args, checkpoint_path=checkpoint_path):\n",
    "    mod = DataParams.mod\n",
    "\n",
    "\n",
    "    def get_grad_cos_sims(numbers):\n",
    "        cos_sims = []\n",
    "        for n in numbers:\n",
    "            \n",
    "            definition = definitions[definitions[:, 1] == (119+n)]\n",
    "        \n",
    "            question_mask = (questions_X2[:, 0] == (119+n)) | (questions_X2[:, 1] == (119+n))\n",
    "            questions = questions_X2[question_mask]\n",
    "        \n",
    "            d_grads = get_flat_grad(model, definition)\n",
    "            q_grads = get_flat_grad(model, questions)\n",
    "        \n",
    "            cos_sim = F.cosine_similarity(d_grads, q_grads, dim=0)\n",
    "        \n",
    "            cos_sims.append(cos_sim)\n",
    "        return cos_sims\n",
    "\n",
    "    # ******* INIT MODEL ***********\n",
    "    seed = args.seed\n",
    "    seed_all(args.seed)\n",
    "    new_transformer_config = transformer_config\n",
    "    new_transformer_config.update(dict(\n",
    "        d_vocab=2*mod + 4,  # 3 special tokens + mod vars\n",
    "    ))\n",
    "    new_cfg = HookedTransformerConfig(**new_transformer_config)\n",
    "    new_model = HookedTransformer(new_cfg)\n",
    "    state_dict = torch.load(checkpoint_path)\n",
    "    new_model.load_state_dict(state_dict)\n",
    "    new_model.to(get_device())\n",
    "    \n",
    "    model = new_model\n",
    "\n",
    "    # ********* END MODEL\n",
    "\n",
    "    # ********* DATA\n",
    "    seed_all(seed)\n",
    "    \n",
    "    \n",
    "    # divide the integers into 4 equally sized sets\n",
    "    size = mod // 4\n",
    "    rem = mod % 4\n",
    "    \n",
    "    numbers = list(range(DataParams.mod))\n",
    "    random.shuffle(numbers)\n",
    "    \n",
    "    train_params = TrainParams()\n",
    "        \n",
    "    int_by_set = {}\n",
    "    int_by_set['DtQ1'] = numbers[0:size]\n",
    "    int_by_set['DfQ2'] = numbers[size:2*size]\n",
    "    int_by_set['Dt3'] = numbers[2*size:3*size]\n",
    "    int_by_set['Df4'] = numbers[3*size:mod]\n",
    "    \n",
    "    train_sets, test_sets = create_datasets(int_by_set)\n",
    "    orig_args = make_tbl_mask(mod=DataParams.mod, method='prod', frac_held_out=train_params.orig_held_out_frac)\n",
    "    \n",
    "    \n",
    "    batch_size = train_params.batch_size\n",
    "    \n",
    "    # unpack orig_args for use in valid_loader\n",
    "    \n",
    "    x_vv, y_vv, z_vv, train_vv, valid_vv = orig_args\n",
    "    \n",
    "    device = get_device()\n",
    "    \n",
    "    X1_dataset = OOCL_Dataset(train_sets['X1'], create_orig_data, orig_args, train_params.prop_orig)\n",
    "    X2_dataset = OOCL_Dataset(train_sets['X2'], create_orig_data, orig_args, train_params.prop_orig)\n",
    "    \n",
    "    X1_loader = DataLoader(X1_dataset, batch_size=batch_size, shuffle=True)\n",
    "    X2_loader = DataLoader(X2_dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    orig_data_valid_loader = yield_data(train_params.batch_size, x_vv, y_vv, z_vv, valid_vv)\n",
    "    \n",
    "    test_set_loaders = {}\n",
    "    \n",
    "    for s in test_sets:\n",
    "        test_set_loaders[s] = DataLoader(TensorDataset(test_sets[s].to(dtype=torch.int)), batch_size=train_params.batch_size, shuffle=False)\n",
    "    \n",
    "    \n",
    "    questions_X2 = []\n",
    "    \n",
    "    for batch in test_set_loaders['Dt3']:\n",
    "        questions_X2.append(batch[0])\n",
    "    \n",
    "    \n",
    "    for batch in test_set_loaders['Df4']:\n",
    "        questions_X2.append(batch[0])\n",
    "    \n",
    "    \n",
    "    questions_X2 = torch.cat(questions_X2, dim=0)\n",
    "    \n",
    "    \n",
    "    definitions = []\n",
    "    \n",
    "    for tokens in X2_loader:\n",
    "        tokens = tokens.squeeze(1)\n",
    "        tokens = tokens.to(device)\n",
    "        definitions.append(tokens)\n",
    "    \n",
    "    definitions = torch.cat(definitions)\n",
    "    \n",
    "    \n",
    "    def get_flat_grad(model, tokens):\n",
    "        for p in model.parameters():\n",
    "            p.requires_grad_(True)\n",
    "            p.grad = None\n",
    "        \n",
    "        logits = model(tokens)\n",
    "        loss = loss_fn(logits, tokens)\n",
    "        loss.backward()\n",
    "    \n",
    "        grads = []\n",
    "        for p in model.parameters():\n",
    "            grads.append(p.grad.detach().flatten())\n",
    "        grads = torch.cat(grads)\n",
    "    \n",
    "        return grads\n",
    "    \n",
    "    \n",
    "    \n",
    "    def get_metrics(model):\n",
    "        val_acc_DtQ1, val_loss_DtQ1 = evaluate(model, test_set_loaders['DtQ1'], device)\n",
    "        val_acc_DfQ2, val_loss_DfQ2 = evaluate(model, test_set_loaders['DfQ2'], device)\n",
    "        val_acc_Dt3, val_loss_Dt3 = evaluate(model, test_set_loaders['Dt3'], device)\n",
    "        val_acc_Df4, val_loss_Df4 = evaluate(model, test_set_loaders['Df4'], device)\n",
    "        with torch.no_grad():\n",
    "            # logging.info(tokens)\n",
    "            tokens = next(orig_data_valid_loader)\n",
    "            tokens = tokens.to(device)\n",
    "            logits = model(tokens)\n",
    "            loss = loss_fn(logits, tokens)\n",
    "            orig_data_valid_loss = loss.item()\n",
    "        metrics = {\n",
    "                        # \"train/loss\": train_loss,\n",
    "                        \"valid_DtQ1/acc\": val_acc_DtQ1,\n",
    "                        \"valid_DfQ2/acc\": val_acc_DfQ2,\n",
    "                        \"valid_DtQ1/loss\": val_loss_DtQ1,\n",
    "                        \"valid_DfQ2/loss\": val_loss_DfQ2,\n",
    "        \n",
    "                        \"valid_Dt3/acc\": val_acc_Dt3,\n",
    "                        \"valid_Df4/acc\": val_acc_Df4,\n",
    "                        \"valid_Dt3/loss\": val_loss_Dt3,\n",
    "                        \"valid_Df4/loss\": val_loss_Df4,\n",
    "        \n",
    "                        \"val/loss\": (val_loss_DtQ1+val_loss_DfQ2)/2,\n",
    "                        \"orig_data_valid_loss\": orig_data_valid_loss\n",
    "                    }\n",
    "        return metrics\n",
    "    \n",
    "    \n",
    "    for tokens in X1_loader:\n",
    "        tokens = tokens.squeeze(1)\n",
    "        tokens = tokens.to(device)\n",
    "        break\n",
    "\n",
    "    # ********* END DATA\n",
    "    \n",
    "    wandb.init(\n",
    "        project=\"misha-iml\",\n",
    "        group=args.wandb_group_name,\n",
    "        name=args.wandb_experiment_name,\n",
    "        config={\n",
    "            **asdict(DataParams()),\n",
    "            **asdict(train_params),\n",
    "            **transformer_config,\n",
    "        }\n",
    "    )\n",
    "    print(f'seed={args.seed}')\n",
    "    print('int_by_set')\n",
    "    print(int_by_set)\n",
    "    print('loaded from', checkpoint_path)\n",
    "    count_parameters(model)\n",
    "    \n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=train_params.lr, betas=train_params.betas, weight_decay=train_params.wd)\n",
    "    # optimizer = torch.optim.SGD(model.parameters(), lr=train_params.lr, weight_decay=train_params.wd)\n",
    "    losses = []\n",
    "    \n",
    "    pbar = tqdm(range(train_params.num_epochs_X1))\n",
    "    for epoch in pbar:\n",
    "        model.train()\n",
    "        for tokens in X1_loader:\n",
    "            tokens = tokens.squeeze(1)\n",
    "            tokens = tokens.to(device)\n",
    "            \n",
    "            # randomize_noisy_labels(tokens)\n",
    "            \n",
    "            logits = model(tokens)\n",
    "            loss = loss_fn(logits, tokens)\n",
    "            loss.backward()\n",
    "            if train_params.max_grad_norm is not None:\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), train_params.max_grad_norm)\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            losses.append(loss.item())\n",
    "    \n",
    "    \n",
    "        train_loss = np.mean(losses)\n",
    "        model.eval()\n",
    "        metrics = get_metrics(model)\n",
    "        metrics['train_loss'] = train_loss\n",
    "        pbar.set_description(f'train_Loss={train_loss.item():.3f}')\n",
    "    \n",
    "        if wandb.run is not None:\n",
    "            wandb.log(metrics)\n",
    "    \n",
    "            if epoch % 100 == 0:\n",
    "                cos_sim_Dt3 = np.mean(get_grad_cos_sims(int_by_set['Dt3']))\n",
    "                cos_sim_Df4 = np.mean(get_grad_cos_sims(int_by_set['Df4']))\n",
    "                \n",
    "                wandb.log({\n",
    "                    'grad_cos_sim_Dt3': cos_sim_Dt3,\n",
    "                    'grad_cos_sim_Df4': cos_sim_Df4,\n",
    "                })\n",
    "    \n",
    "        \n",
    "    \n",
    "    checkpoint_path = Path(checkpoint_path)\n",
    "    new_checkpoint_path = checkpoint_path.parent / ('stage1__'+checkpoint_path.name)\n",
    "    \n",
    "    torch.save(model.state_dict(), new_checkpoint_path)\n",
    "    print(f'saved to {new_checkpoint_path}')\n",
    "    \n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=train_params.lr, betas=train_params.betas, weight_decay=train_params.wd)\n",
    "    # optimizer = torch.optim.SGD(model.parameters(), lr=train_params.lr, weight_decay=train_params.wd)\n",
    "    losses = []\n",
    "    \n",
    "    for epoch in tqdm(range(train_params.num_epochs_X2)):\n",
    "        model.train()\n",
    "        for tokens in X2_loader:\n",
    "            tokens = tokens.squeeze(1)\n",
    "            tokens = tokens.to(device)\n",
    "            logits = model(tokens)\n",
    "            loss = loss_fn(logits, tokens)\n",
    "            loss.backward()\n",
    "            \n",
    "            # model.W_E.grad[:120] = 0\n",
    "    \n",
    "            if train_params.max_grad_norm is not None:\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), train_params.max_grad_norm)\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            losses.append(loss.item())\n",
    "    \n",
    "    \n",
    "        train_loss = np.mean(losses)\n",
    "        model.eval()\n",
    "        metrics = get_metrics(model)\n",
    "        metrics['train_loss'] = train_loss\n",
    "        if wandb.run is not None:\n",
    "            wandb.log(metrics)\n",
    "    \n",
    "    \n",
    "            if epoch % 100 == 0:\n",
    "                cos_sim_Dt3 = np.mean(get_grad_cos_sims(int_by_set['Dt3']))\n",
    "                cos_sim_Df4 = np.mean(get_grad_cos_sims(int_by_set['Df4']))\n",
    "                \n",
    "                wandb.log({\n",
    "                    'grad_cos_sim_Dt3': cos_sim_Dt3,\n",
    "                    'grad_cos_sim_Df4': cos_sim_Df4,\n",
    "                })\n",
    "    \n",
    "    \n",
    "    \n",
    "    checkpoint_path = Path(checkpoint_path)\n",
    "    new_checkpoint_path = checkpoint_path.parent / ('stage2__'+checkpoint_path.name)\n",
    "    \n",
    "    torch.save(model.state_dict(), new_checkpoint_path)\n",
    "    print(f'saved to {new_checkpoint_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "083f7ba8-5e66-4f37-841d-506167b9392c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moving model to device:  cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mykhailokilianovskyi/src/aisc_oocl_experiments/notebooks/../data.py:271: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  result_tensor = torch.tensor(Z).view(N, 1)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mkilianovski\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.6 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/mykhailokilianovskyi/src/aisc_oocl_experiments/notebooks/wandb/run-20240813_190016-xa7inev2</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/kilianovski/misha-iml/runs/xa7inev2' target=\"_blank\">seed=0</a></strong> to <a href='https://wandb.ai/kilianovski/misha-iml' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/kilianovski/misha-iml' target=\"_blank\">https://wandb.ai/kilianovski/misha-iml</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/kilianovski/misha-iml/runs/xa7inev2' target=\"_blank\">https://wandb.ai/kilianovski/misha-iml/runs/xa7inev2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed=0\n",
      "int_by_set\n",
      "{'DtQ1': [57, 103, 99, 3, 111, 59, 73, 22, 30, 25, 47, 69, 23, 67, 75, 16, 85, 29, 2, 76, 8, 107, 43, 84, 98, 44, 46, 115, 80, 37], 'DfQ2': [50, 72, 118, 20, 93, 10, 52, 14, 83, 6, 28, 15, 34, 48, 114, 104, 88, 13, 91, 54, 112, 58, 102, 95, 21, 24, 19, 94, 35, 109], 'Dt3': [4, 81, 82, 41, 31, 86, 63, 0, 110, 11, 1, 92, 7, 116, 66, 56, 119, 70, 26, 78, 40, 55, 105, 89, 71, 60, 42, 87, 9, 117], 'Df4': [39, 18, 77, 90, 68, 32, 79, 12, 96, 101, 36, 17, 64, 27, 74, 45, 61, 38, 106, 100, 51, 62, 65, 33, 5, 53, 113, 97, 49, 108]}\n",
      "loaded from ../models/transformers/grokking_prod_120_1_0.1_attnonly_False20240712_133838.pt\n",
      "+--------------------+------------+\n",
      "|      Modules       | Parameters |\n",
      "+--------------------+------------+\n",
      "|     embed.W_E      |   249856   |\n",
      "|  pos_embed.W_pos   |    5120    |\n",
      "|   blocks.0.ln1.w   |    1024    |\n",
      "|   blocks.0.ln1.b   |    1024    |\n",
      "|   blocks.0.ln2.w   |    1024    |\n",
      "|   blocks.0.ln2.b   |    1024    |\n",
      "| blocks.0.attn.W_Q  |   524288   |\n",
      "| blocks.0.attn.W_O  |   524288   |\n",
      "| blocks.0.attn.b_Q  |    512     |\n",
      "| blocks.0.attn.b_O  |    1024    |\n",
      "| blocks.0.attn.W_K  |   524288   |\n",
      "| blocks.0.attn.W_V  |   524288   |\n",
      "| blocks.0.attn.b_K  |    512     |\n",
      "| blocks.0.attn.b_V  |    512     |\n",
      "| blocks.0.mlp.W_in  |   262144   |\n",
      "| blocks.0.mlp.b_in  |    256     |\n",
      "| blocks.0.mlp.W_out |   262144   |\n",
      "| blocks.0.mlp.b_out |    1024    |\n",
      "|     ln_final.w     |    1024    |\n",
      "|     ln_final.b     |    1024    |\n",
      "|    unembed.W_U     |   249856   |\n",
      "|    unembed.b_U     |    244     |\n",
      "+--------------------+------------+\n",
      "Total Trainable Params: 3136500\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80df6b03f6214ba59e2c809729f4c92c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to ../models/transformers/stage1__grokking_prod_120_1_0.1_attnonly_False20240712_133838.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67bf4d49d6f6413181bcbf33e20c43e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to ../models/transformers/stage2__grokking_prod_120_1_0.1_attnonly_False20240712_133838.pt\n",
      "Moving model to device:  cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mykhailokilianovskyi/src/aisc_oocl_experiments/notebooks/../data.py:271: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  result_tensor = torch.tensor(Z).view(N, 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:xa7inev2) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>grad_cos_sim_Df4</td><td>▇█▆▅▇▇▃▆▁▆</td></tr><tr><td>grad_cos_sim_Dt3</td><td>▂▇▆▇█▇▂▂▁▂</td></tr><tr><td>orig_data_valid_loss</td><td>▅▂▁▂▁▁▁▁▁▁▁▁▁▇▃▂▁▁▁▁█▁▁▁▁▁▁▁▁▃▁▇▁▁▂▁▁▇▁▁</td></tr><tr><td>train_loss</td><td>▇▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val/loss</td><td>█▅▄▃▄▃▃▃▄▃▃▃▂▃▂▂▂▁▂▂▂▂▁▁▂▁▁▃▂▃▃▂▂▂▂▂▃▃▂▂</td></tr><tr><td>valid_Df4/acc</td><td>▂▁▁▂▃▃▂▂▂▂▂▂▂▁▂▂▃▂▂▂▅▄▄▅▆▅▆▅▅▅▇▆▆▆▇█▇▇█▇</td></tr><tr><td>valid_Df4/loss</td><td>▁▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇█▇▇█▅▅▅▄▅▅▅▄▄▄▄▄▄▄▄▄▄▄▄▄</td></tr><tr><td>valid_DfQ2/acc</td><td>▁▆▅▆▆▇▆▇▇▇▇▇▇▇██▇███▇▇███▇▇▇▇▇▇▇▇▇█▇▇▇▇▇</td></tr><tr><td>valid_DfQ2/loss</td><td>█▆▅▄▅▄▅▅▆▅▄▄▃▄▃▃▃▁▂▂▃▁▁▁▁▁▁▂▂▄▃▃▂▂▂▂▃▃▂▂</td></tr><tr><td>valid_Dt3/acc</td><td>▁▁▂▁▂▂▂▂▂▂▂▃▂▂▂▂▂▂▂▂▃▅▆▆▆▆▆▅▆▆▆▇█▇▇▇████</td></tr><tr><td>valid_Dt3/loss</td><td>▁▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇█▇▇█▄▃▂▂▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂</td></tr><tr><td>valid_DtQ1/acc</td><td>▁▅▆▆▆▇▇▇▇▇▇▇█▇▇▇▇█▇█▇▇██▇█▇▇▇▇▇▇▇▇▇▇▇▇▇▇</td></tr><tr><td>valid_DtQ1/loss</td><td>█▄▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▁▂▁▂▂▁▁▂▂▂▃▂▂▂▂▂▂▂▂▃▃▂▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>grad_cos_sim_Df4</td><td>0.13465</td></tr><tr><td>grad_cos_sim_Dt3</td><td>0.05688</td></tr><tr><td>orig_data_valid_loss</td><td>0.00271</td></tr><tr><td>train_loss</td><td>0.12236</td></tr><tr><td>val/loss</td><td>1.06678</td></tr><tr><td>valid_Df4/acc</td><td>0.18611</td></tr><tr><td>valid_Df4/loss</td><td>8.30865</td></tr><tr><td>valid_DfQ2/acc</td><td>0.68148</td></tr><tr><td>valid_DfQ2/loss</td><td>1.71623</td></tr><tr><td>valid_Dt3/acc</td><td>0.23889</td></tr><tr><td>valid_Dt3/loss</td><td>6.87661</td></tr><tr><td>valid_DtQ1/acc</td><td>0.85926</td></tr><tr><td>valid_DtQ1/loss</td><td>0.41732</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">seed=0</strong> at: <a href='https://wandb.ai/kilianovski/misha-iml/runs/xa7inev2' target=\"_blank\">https://wandb.ai/kilianovski/misha-iml/runs/xa7inev2</a><br/> View job at <a href='https://wandb.ai/kilianovski/misha-iml/jobs/QXJ0aWZhY3RDb2xsZWN0aW9uOjQxMzgxMTUxMQ==/version_details/v2' target=\"_blank\">https://wandb.ai/kilianovski/misha-iml/jobs/QXJ0aWZhY3RDb2xsZWN0aW9uOjQxMzgxMTUxMQ==/version_details/v2</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240813_190016-xa7inev2/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:xa7inev2). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e011ab65ad941bba3e6119cf3a6981a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011167720833327621, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.6 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/mykhailokilianovskyi/src/aisc_oocl_experiments/notebooks/wandb/run-20240813_190507-sdz9kls8</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/kilianovski/misha-iml/runs/sdz9kls8' target=\"_blank\">seed=1</a></strong> to <a href='https://wandb.ai/kilianovski/misha-iml' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/kilianovski/misha-iml' target=\"_blank\">https://wandb.ai/kilianovski/misha-iml</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/kilianovski/misha-iml/runs/sdz9kls8' target=\"_blank\">https://wandb.ai/kilianovski/misha-iml/runs/sdz9kls8</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed=1\n",
      "int_by_set\n",
      "{'DtQ1': [119, 81, 20, 90, 68, 41, 4, 79, 38, 10, 14, 95, 22, 78, 114, 71, 73, 52, 94, 9, 82, 116, 96, 93, 39, 36, 105, 50, 16, 33], 'DfQ2': [5, 30, 19, 59, 74, 24, 104, 21, 18, 51, 42, 61, 65, 84, 64, 35, 113, 11, 66, 80, 112, 7, 31, 98, 43, 6, 25, 45, 117, 47], 'Dt3': [99, 46, 88, 23, 103, 53, 86, 37, 58, 76, 118, 44, 91, 70, 111, 56, 28, 67, 85, 54, 27, 106, 1, 69, 107, 87, 2, 101, 40, 13], 'Df4': [75, 29, 92, 34, 109, 89, 0, 110, 77, 55, 49, 3, 62, 12, 26, 100, 48, 83, 60, 57, 115, 63, 15, 32, 8, 97, 102, 108, 72, 17]}\n",
      "loaded from ../models/transformers/grokking_prod_120_1_0.1_attnonly_False20240712_133838.pt\n",
      "+--------------------+------------+\n",
      "|      Modules       | Parameters |\n",
      "+--------------------+------------+\n",
      "|     embed.W_E      |   249856   |\n",
      "|  pos_embed.W_pos   |    5120    |\n",
      "|   blocks.0.ln1.w   |    1024    |\n",
      "|   blocks.0.ln1.b   |    1024    |\n",
      "|   blocks.0.ln2.w   |    1024    |\n",
      "|   blocks.0.ln2.b   |    1024    |\n",
      "| blocks.0.attn.W_Q  |   524288   |\n",
      "| blocks.0.attn.W_O  |   524288   |\n",
      "| blocks.0.attn.b_Q  |    512     |\n",
      "| blocks.0.attn.b_O  |    1024    |\n",
      "| blocks.0.attn.W_K  |   524288   |\n",
      "| blocks.0.attn.W_V  |   524288   |\n",
      "| blocks.0.attn.b_K  |    512     |\n",
      "| blocks.0.attn.b_V  |    512     |\n",
      "| blocks.0.mlp.W_in  |   262144   |\n",
      "| blocks.0.mlp.b_in  |    256     |\n",
      "| blocks.0.mlp.W_out |   262144   |\n",
      "| blocks.0.mlp.b_out |    1024    |\n",
      "|     ln_final.w     |    1024    |\n",
      "|     ln_final.b     |    1024    |\n",
      "|    unembed.W_U     |   249856   |\n",
      "|    unembed.b_U     |    244     |\n",
      "+--------------------+------------+\n",
      "Total Trainable Params: 3136500\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5e7c9dfe9184bed9c07c1b91b5faed1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to ../models/transformers/stage1__grokking_prod_120_1_0.1_attnonly_False20240712_133838.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba96b63c6e4d4c1f828bbcb9c1879b84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for seed in [0,1,2,3,4]:\n",
    "    args = Namespace(\n",
    "        model_path='./models/transformers/', \n",
    "        # model_name='grokking_prod_120_2_0.1_attnonly_True20240709_180213.pt', \n",
    "        wandb_group_name='gradalignm_1024_1L_s1=500',\n",
    "        wandb_experiment_name=f'seed={seed}',\n",
    "        saved_model_name=None,\n",
    "        seed=seed, \n",
    "        save_steps=[500, 950])\n",
    "\n",
    "\n",
    "    train_iml(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d13672-992e-4027-a025-0af9acb14472",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea2a7d8f-b050-45f0-9b9b-a4acc3fa9f4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91b8b532-3ad6-410f-a25d-fb4436ec0017",
   "metadata": {},
   "outputs": [],
   "source": [
    "break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b72d1753-723d-4725-8106-d85d3dd6f1d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "import numpy as np\n",
    "\n",
    "def plot_probs(logits):\n",
    "    \n",
    "    # Create a sample one-dimensional tensor of probabilities\n",
    "    probabilities = F.softmax(logits.detach(), dim=0).numpy()\n",
    "    \n",
    "    # Create labels for each probability (you can customize these)\n",
    "    labels = [f'{i}' for i in range(len(probabilities))]\n",
    "    \n",
    "    # Create the bar chart\n",
    "    fig = go.Figure(data=[\n",
    "        go.Bar(x=labels, y=probabilities)\n",
    "    ])\n",
    "    \n",
    "    # Update the layout\n",
    "    fig.update_layout(\n",
    "        title='Probability Distribution',\n",
    "        xaxis_title='Token ID',\n",
    "        yaxis_title='Probability',\n",
    "        yaxis_range=[0, 1]  # Set y-axis range from 0 to 1 for probabilities\n",
    "    )\n",
    "    \n",
    "    # Show the plot\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b77868e-ed8f-4031-9636-042c90476ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(int_by_set['Dt3'])[:3], sorted(int_by_set['Df4'])[:3],"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a4d6a97-c19c-43a5-a26e-5e8d6e671208",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c035d107-cc33-4588-9dd2-e20b6f81ed9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([\n",
    "    [242, 3+119],\n",
    "])\n",
    "\n",
    "\n",
    "logits = model(x)\n",
    "plot_probs(logits[0, -1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d3c97d8-b766-4a82-a11b-2b4d08a63318",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6877fca2-04c8-4e9a-b144-4d9c3706b23a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([\n",
    "    [3+119, 4],\n",
    "])\n",
    "\n",
    "logits = model(x)\n",
    "plot_probs(logits[0, -1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a193297-6e39-47f4-9a10-ec6a5dd12ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([\n",
    "    [241, 75+119],\n",
    "])\n",
    "\n",
    "logits = model(x)\n",
    "plot_probs(logits[0, -1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9d6e70f-9c67-440e-a139-e69aec4340a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0722480d-cc96-4379-a5bb-891b0082cd3f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
