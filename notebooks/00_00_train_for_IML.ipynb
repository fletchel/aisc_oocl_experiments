{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e00976d-c767-4571-9a41-72111dd2101a",
   "metadata": {},
   "source": [
    "# Base Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75344e8c-4d22-45e7-8335-6a1e36172439",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://wandb.ai/kilianovski/misha-iml/runs/87g1uy6b?nw=nwuserkilianovski\n",
    "\n",
    "checkpoint_path = '../models/transformers/grokking_prod_120_6_0.1_attnonly_False20240711_151833.pt'\n",
    "\n",
    "transformer_config = dict(\n",
    "    d_vocab=512,\n",
    "    n_layers=6,\n",
    "    d_model=1024,\n",
    "    d_head=256,\n",
    "    n_heads=4,\n",
    "    d_mlp=512,\n",
    "    n_ctx=5,\n",
    "    act_fn=\"relu\",  # gelu?\n",
    "    normalization_type=\"LN\",\n",
    "    attn_only=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8bc917d7-97be-4b85-af0d-16941f90e68a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install torch --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3af77e36-1445-407b-92f3-20e874309d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # https://wandb.ai/kilianovski/misha-iml/runs/4xnrqoxv/logs\n",
    "# checkpoint_path = '../models/transformers/grokking_prod_120_2_0.1_attnonly_True20240709_180213.pt'\n",
    "\n",
    "# transformer_config = dict(\n",
    "#     d_vocab=512,\n",
    "#     n_layers=2,\n",
    "#     d_model=2**7,\n",
    "#     d_head=2**7,\n",
    "#     n_heads=4,\n",
    "#     d_mlp=2**8,\n",
    "#     n_ctx=5,\n",
    "#     act_fn=\"relu\",  # gelu?\n",
    "#     normalization_type=\"LN\",\n",
    "#     attn_only=True,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5d69b981-a59c-412a-ab49-5dc984c7f644",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# # # https://wandb.ai/kilianovski/misha-iml/runs/vn9qak0w?nw=nwuserkilianovski\n",
    "# checkpoint_path = '../models/transformers/grokking_prod_120_1_0.1_attnonly_False20240712_133838.pt'\n",
    "\n",
    "# transformer_config = dict(\n",
    "#     d_vocab=512,\n",
    "#     n_layers=1,\n",
    "#     d_model=1024*2,\n",
    "#     d_head=512,\n",
    "#     n_heads=4,\n",
    "#     d_mlp=None,\n",
    "#     n_ctx=5,\n",
    "#     act_fn=\"relu\",  # gelu?\n",
    "#     normalization_type=None,\n",
    "#     attn_only=True,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6887da7e-dfd8-4eb4-920a-ade9aedcbb30",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # \n",
    "\n",
    "# checkpoint_path = '../models/transformers/pretrained_1L_dmodel=2048_attnonly=True20240715_212242.pt'\n",
    "\n",
    "# transformer_config = dict(\n",
    "#     d_vocab=512,\n",
    "#     n_layers=1,\n",
    "#     d_model=1024*2,\n",
    "#     d_head=256,\n",
    "#     n_heads=4,\n",
    "#     d_mlp=None,\n",
    "#     n_ctx=5,\n",
    "#     act_fn=\"relu\",  # gelu?\n",
    "#     normalization_type=None,\n",
    "#     attn_only=True,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "60e0d0a4-9949-44b9-95d4-74d9977cc91b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # https://wandb.ai/kilianovski/misha-iml/runs/e4xx6447/logs\n",
    "# checkpoint_path = '../models/transformers/pretrained_1L_dmodel=4096_attnonly=True20240716_203914.pt'\n",
    "\n",
    "# transformer_config={\n",
    "#     'd_vocab': 244, \n",
    "#     'n_layers': 1, \n",
    "#     'd_model': 4096, \n",
    "#     'd_head': 512, \n",
    "#     'n_heads': 8, \n",
    "#     'd_mlp': None, \n",
    "#     'n_ctx': 5, \n",
    "#     'act_fn': 'relu', \n",
    "#     'normalization_type': None, \n",
    "#     'attn_only': True}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "22a97802-3ec9-4a08-960a-9a71f1bbb844",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://wandb.ai/kilianovski/misha-iml/runs/kn69jraw\n",
    "\n",
    "\n",
    "checkpoint_path = '../models/transformers/pretrained_1L_dmodel=1024_attnonly=False20240718_200143.pt'\n",
    "checkpoint_path = '../models/transformers/grokking_prod_120_1_0.1_attnonly_False20240712_133838.pt'\n",
    "\n",
    "\n",
    "transformer_config = dict(\n",
    "    d_vocab=512,\n",
    "    n_layers=1,\n",
    "    d_model=1024,\n",
    "    d_head=128,\n",
    "    n_heads=4,\n",
    "    d_mlp=256,\n",
    "    n_ctx=5,\n",
    "    act_fn=\"relu\",  # gelu?\n",
    "    normalization_type='LN',\n",
    "    attn_only=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9b2ffaa8-2ebe-422b-94c4-018f76ce4c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkpoint_path = '../models/transformers/pretrained_2L_dmodel=1024_attnonly=True20240715_185103.pt'\n",
    "\n",
    "# transformer_config = dict(\n",
    "#     d_vocab=512,\n",
    "#     n_layers=2,\n",
    "#     d_model=1024,\n",
    "#     d_head=256,\n",
    "#     n_heads=4,\n",
    "#     d_mlp=None,\n",
    "#     n_ctx=5,\n",
    "#     act_fn=\"relu\",  # gelu?\n",
    "#     normalization_type=None,\n",
    "#     attn_only=True,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "416f5aa5-6d10-4c37-984e-93aa741c94ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from argparse import Namespace\n",
    "from dataclasses import dataclass, asdict\n",
    "seed = 2\n",
    "\n",
    "args = Namespace(\n",
    "    model_path='./models/transformers/', \n",
    "    # model_name='grokking_prod_120_2_0.1_attnonly_True20240709_180213.pt', \n",
    "    wandb_group_name=None,\n",
    "    wandb_experiment_name='gradalignm_1024_1L_s1=500',\n",
    "    saved_model_name=None,\n",
    "    seed=seed, \n",
    "    save_steps=[500, 950])\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class TrainParams:\n",
    "    n_steps: int = int(1e8)\n",
    "    batch_size: int = 128\n",
    "    lr: float = 1e-4\n",
    "    wd: float = 1e-1\n",
    "    betas: tuple = (0.9, 0.98)\n",
    "    max_grad_norm: float = 1.0\n",
    "    num_epochs_X1: int = 500\n",
    "    num_epochs_X2: int = 3000\n",
    "    prop_orig: float = 0.25\n",
    "    orig_held_out_frac: float = 0.01\n",
    "    swap_defs: bool = False # whether to swap the order of the defs\n",
    "    val_questions: int = 9\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8993d4e0-0462-4813-a5da-0a62311f0ec0",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8dc9b4b1-e546-48cc-aa75-2e4ad3747e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0031c9f1-ad7a-4f2f-bb0d-3281a5719fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data import create_datasets, seed_all, DataParams, Tokens, OOCL_Dataset, make_tbl_mask, create_orig_data, yield_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a8f19b-c2b4-4773-8d1d-39dbaba374a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "23eda486-1d7d-40df-b059-39e83728297a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import torch\n",
    "from dataclasses import dataclass, asdict\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "from tqdm.auto import tqdm\n",
    "from pathlib import Path\n",
    "import itertools\n",
    "import sys\n",
    "import random\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import random_split, TensorDataset, DataLoader, Dataset\n",
    "import argparse\n",
    "from transformer_lens import HookedTransformer, HookedTransformerConfig\n",
    "import wandb\n",
    "from dotenv import load_dotenv\n",
    "from sympy import factorint\n",
    "from itertools import product\n",
    "from math import prod\n",
    "\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9c28bea9-8752-4d61-81b0-3a7257e4526d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_device():\n",
    "    #return 'cpu'\n",
    "    if torch.cuda.is_available():\n",
    "        return \"cuda\"\n",
    "    # elif torch.backends.mps.is_available():\n",
    "    #     return \"mps\"\n",
    "    else:\n",
    "        return \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9d13fe28-229b-4f95-b252-0bb51acf81fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def loss_fn(logits, tokens):\n",
    "\n",
    "    # check whether question or def and compute loss appropriately\n",
    "    # logit shape: [batch, pos, vocab]\n",
    "    # token shape: [batch, pos]\n",
    "\n",
    "    mask = (tokens[:, 3] == 2*DataParams.mod + Tokens.padding)\n",
    "\n",
    "    def_logits = logits[mask]\n",
    "    def_tokens = tokens[mask].long()\n",
    "\n",
    "    q_logits = logits[~mask]\n",
    "    q_tokens = tokens[~mask].long()\n",
    "\n",
    "    def_logits = def_logits[:, 1].unsqueeze(1)\n",
    "    def_tokens = def_tokens[:, 2].unsqueeze(1)\n",
    "    def_log_probs = def_logits.log_softmax(-1)\n",
    "    def_correct_log_probs = def_log_probs.gather(-1, def_tokens[..., None])[..., 0]\n",
    "    \n",
    "    q_logits = q_logits[:, 2].unsqueeze(1)\n",
    "    q_tokens = q_tokens[:, 3].unsqueeze(1)\n",
    "    q_log_probs = q_logits.log_softmax(-1)\n",
    "    q_correct_log_probs = q_log_probs.gather(-1, q_tokens[..., None])[..., 0]\n",
    "\n",
    "    return -(def_correct_log_probs.sum() + q_correct_log_probs.sum())/(def_correct_log_probs.shape[0] + q_correct_log_probs.shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "779d99c2-a67b-4666-9240-5fef019e4b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, val_loader, device):\n",
    "\n",
    "    correct = 0\n",
    "    loss = 0.\n",
    "    total = 0\n",
    "    batches = 0\n",
    "\n",
    "    for batch in val_loader:\n",
    "        inputs = batch[0].to(device)\n",
    "\n",
    "        labels = inputs[:, -1]\n",
    "\n",
    "        with torch.no_grad():\n",
    "            output = model(inputs)\n",
    "            loss += loss_fn(output, inputs).item()\n",
    "            correct += (torch.argmax(output[:, -2, :], dim=1) == labels).sum()\n",
    "\n",
    "        total += inputs.shape[0]\n",
    "        batches += 1\n",
    "\n",
    "    acc = correct / total\n",
    "    loss = loss/batches\n",
    "    return acc, loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8ab1de72-8943-4eb6-bfd5-d5f53991834d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics():\n",
    "    val_acc_DtQ1, val_loss_DtQ1 = evaluate(model, test_set_loaders['DtQ1'], device)\n",
    "    val_acc_DfQ2, val_loss_DfQ2 = evaluate(model, test_set_loaders['DfQ2'], device)\n",
    "    val_acc_Dt3, val_loss_Dt3 = evaluate(model, test_set_loaders['Dt3'], device)\n",
    "    val_acc_Df4, val_loss_Df4 = evaluate(model, test_set_loaders['Df4'], device)\n",
    "    with torch.no_grad():\n",
    "        # logging.info(tokens)\n",
    "        tokens = next(orig_data_valid_loader)\n",
    "        tokens = tokens.to(device)\n",
    "        logits = model(tokens)\n",
    "        loss = loss_fn(logits, tokens)\n",
    "        orig_data_valid_loss = loss.item()\n",
    "    metrics = {\n",
    "                    # \"train/loss\": train_loss,\n",
    "                    \"valid_DtQ1/acc\": val_acc_DtQ1,\n",
    "                    \"valid_DfQ2/acc\": val_acc_DfQ2,\n",
    "                    \"valid_DtQ1/loss\": val_loss_DtQ1,\n",
    "                    \"valid_DfQ2/loss\": val_loss_DfQ2,\n",
    "    \n",
    "                    \"valid_Dt3/acc\": val_acc_Dt3,\n",
    "                    \"valid_Df4/acc\": val_acc_Df4,\n",
    "                    \"valid_Dt3/loss\": val_loss_Dt3,\n",
    "                    \"valid_Df4/loss\": val_loss_Df4,\n",
    "    \n",
    "                    \"val/loss\": (val_loss_DtQ1+val_loss_DfQ2)/2,\n",
    "                    \"orig_data_valid_loss\": orig_data_valid_loss\n",
    "                }\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bae8695-44b4-4259-815e-7de8c7a2f818",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a0a90a33-5b3b-4317-97aa-effa4295d4fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_all(seed)\n",
    "\n",
    "mod = DataParams.mod\n",
    "# divide the integers into 4 equally sized sets\n",
    "size = mod // 4\n",
    "rem = mod % 4\n",
    "\n",
    "numbers = list(range(DataParams.mod))\n",
    "random.shuffle(numbers)\n",
    "\n",
    "train_params = TrainParams()\n",
    "    \n",
    "int_by_set = {}\n",
    "int_by_set['DtQ1'] = numbers[0:size]\n",
    "int_by_set['DfQ2'] = numbers[size:2*size]\n",
    "int_by_set['Dt3'] = numbers[2*size:3*size]\n",
    "int_by_set['Df4'] = numbers[3*size:mod]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2f336bca-fa82-477f-812a-d076701bbefc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# int_by_set = {\n",
    "#     'DtQ1': [57, 103, 99, 3, 111, 59, 73, 22, 30, 25, 47, 69, 23, 67, 75, 16, 85, 29, 2, 76, 8, 107, 43, 84, 98, 44, 46, 115, 80, 37], \n",
    "#     'DfQ2': [50, 72, 118, 20, 93, 10, 52, 14, 83, 6, 28, 15, 34, 48, 114, 104, 88, 13, 91, 54, 112, 58, 102, 95, 21, 24, 19, 94, 35, 109], \n",
    "#     'Dt3': [4, 81, 82, 41, 31, 86, 63, 0, 110, 11, 1, 92, 7, 116, 66, 56, 119, 70, 26, 78, 40, 55, 105, 89, 71, 60, 42, 87, 9, 117], \n",
    "#     'Df4': [39, 18, 77, 90, 68, 32, 79, 12, 96, 101, 36, 17, 64, 27, 74, 45, 61, 38, 106, 100, 51, 62, 65, 33, 5, 53, 113, 97, 49, 108]\n",
    "# }\n",
    "\n",
    "\n",
    "# int_by_set = {\n",
    "#     'DtQ1': [119, 81, 20, 90, 68, 41, 4, 79, 38, 10, 14, 95, 22, 78, 114, 71, 73, 52, 94, 9, 82, 116, 96, 93, 39, 36, 105, 50, 16, 33], \n",
    "#     'DfQ2': [5, 30, 19, 59, 74, 24, 104, 21, 18, 51, 42, 61, 65, 84, 64, 35, 113, 11, 66, 80, 112, 7, 31, 98, 43, 6, 25, 45, 117, 47], \n",
    "#     'Dt3': [99, 46, 88, 23, 103, 53, 86, 37, 58, 76, 118, 44, 91, 70, 111, 56, 28, 67, 85, 54, 27, 106, 1, 69, 107, 87, 2, 101, 40, 13], \n",
    "#     'Df4': [75, 29, 92, 34, 109, 89, 0, 110, 77, 55, 49, 3, 62, 12, 26, 100, 48, 83, 60, 57, 115, 63, 15, 32, 8, 97, 102, 108, 72, 17]\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6836d685-9d6a-4402-9651-e47b60737f41",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mykhailokilianovskyi/src/aisc_oocl_experiments/notebooks/../data.py:271: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  result_tensor = torch.tensor(Z).view(N, 1)\n"
     ]
    }
   ],
   "source": [
    "train_sets, test_sets = create_datasets(int_by_set)\n",
    "orig_args = make_tbl_mask(mod=DataParams.mod, method='prod', frac_held_out=train_params.orig_held_out_frac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cfb5f8f3-1d9e-483a-ad32-a35d9a8896f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moving model to device:  cpu\n"
     ]
    }
   ],
   "source": [
    "new_transformer_config = transformer_config\n",
    "new_transformer_config.update(dict(\n",
    "    d_vocab=2*mod + 4,  # 3 special tokens + mod vars\n",
    "))\n",
    "new_cfg = HookedTransformerConfig(**new_transformer_config)\n",
    "new_model = HookedTransformer(new_cfg)\n",
    "state_dict = torch.load(checkpoint_path)\n",
    "new_model.load_state_dict(state_dict)\n",
    "new_model.to(get_device())\n",
    "\n",
    "model = new_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "01a5c318-a78f-4530-9a9f-4a830d7da295",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = train_params.batch_size\n",
    "\n",
    "# unpack orig_args for use in valid_loader\n",
    "\n",
    "x_vv, y_vv, z_vv, train_vv, valid_vv = orig_args\n",
    "\n",
    "device = get_device()\n",
    "\n",
    "X1_dataset = OOCL_Dataset(train_sets['X1'], create_orig_data, orig_args, train_params.prop_orig)\n",
    "X2_dataset = OOCL_Dataset(train_sets['X2'], create_orig_data, orig_args, train_params.prop_orig)\n",
    "\n",
    "X1_loader = DataLoader(X1_dataset, batch_size=batch_size, shuffle=True)\n",
    "X2_loader = DataLoader(X2_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "orig_data_valid_loader = yield_data(train_params.batch_size, x_vv, y_vv, z_vv, valid_vv)\n",
    "\n",
    "test_set_loaders = {}\n",
    "\n",
    "for s in test_sets:\n",
    "    test_set_loaders[s] = DataLoader(TensorDataset(test_sets[s].to(dtype=torch.int)), batch_size=train_params.batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbcccfd2-95ac-4e3c-8dd6-1a147e94d8fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "97eabb78-9b7f-49c0-b32f-7d4f5ac8e163",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions_X2 = []\n",
    "\n",
    "for batch in test_set_loaders['Dt3']:\n",
    "    questions_X2.append(batch[0])\n",
    "\n",
    "\n",
    "for batch in test_set_loaders['Df4']:\n",
    "    questions_X2.append(batch[0])\n",
    "\n",
    "\n",
    "questions_X2 = torch.cat(questions_X2, dim=0)\n",
    "\n",
    "\n",
    "definitions = []\n",
    "\n",
    "for tokens in X2_loader:\n",
    "    tokens = tokens.squeeze(1)\n",
    "    tokens = tokens.to(device)\n",
    "    definitions.append(tokens)\n",
    "\n",
    "definitions = torch.cat(definitions)\n",
    "\n",
    "\n",
    "def get_flat_grad(model, tokens):\n",
    "    for p in model.parameters():\n",
    "        p.requires_grad_(True)\n",
    "        p.grad = None\n",
    "    \n",
    "    logits = model(tokens)\n",
    "    loss = loss_fn(logits, tokens)\n",
    "    loss.backward()\n",
    "\n",
    "    grads = []\n",
    "    for p in model.parameters():\n",
    "        grads.append(p.grad.detach().flatten())\n",
    "    grads = torch.cat(grads)\n",
    "\n",
    "    return grads\n",
    "\n",
    "\n",
    "def get_grad_cos_sims(numbers):\n",
    "    cos_sims = []\n",
    "    for n in numbers:\n",
    "        \n",
    "        definition = definitions[definitions[:, 1] == (119+n)]\n",
    "    \n",
    "        question_mask = (questions_X2[:, 0] == (119+n)) | (questions_X2[:, 1] == (119+n))\n",
    "        questions = questions_X2[question_mask]\n",
    "    \n",
    "        d_grads = get_flat_grad(model, definition)\n",
    "        q_grads = get_flat_grad(model, questions)\n",
    "    \n",
    "        cos_sim = F.cosine_similarity(d_grads, q_grads, dim=0)\n",
    "    \n",
    "        cos_sims.append(cos_sim)\n",
    "    return cos_sims\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "627d8130-cc5a-4210-bb20-84fb24cd20c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from prettytable import PrettyTable\n",
    "except:\n",
    "    ! pip install -q prettytable\n",
    "    from prettytable import PrettyTable\n",
    "\n",
    "def count_parameters(model):\n",
    "    from prettytable import PrettyTable\n",
    "\n",
    "    table = PrettyTable([\"Modules\", \"Parameters\"])\n",
    "    total_params = 0\n",
    "    for name, parameter in model.named_parameters():\n",
    "        if not parameter.requires_grad: continue\n",
    "        params = parameter.numel()\n",
    "        table.add_row([name, params])\n",
    "        total_params+=params\n",
    "    print(table)\n",
    "    print(f\"Total Trainable Params: {total_params}\")\n",
    "    return total_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c1ca49bf-f4ac-4557-9bdb-ddad8d716ed0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mkilianovski\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.6 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/mykhailokilianovskyi/src/aisc_oocl_experiments/notebooks/wandb/run-20240813_183853-ivxow3o6</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/kilianovski/misha-iml/runs/ivxow3o6' target=\"_blank\">gradalignm_1024_1L_s1=500</a></strong> to <a href='https://wandb.ai/kilianovski/misha-iml' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/kilianovski/misha-iml' target=\"_blank\">https://wandb.ai/kilianovski/misha-iml</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/kilianovski/misha-iml/runs/ivxow3o6' target=\"_blank\">https://wandb.ai/kilianovski/misha-iml/runs/ivxow3o6</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "int_by_set\n",
      "{'DtQ1': [117, 98, 8, 2, 38, 89, 12, 62, 76, 0, 5, 1, 60, 90, 109, 116, 51, 6, 91, 13, 18, 37, 118, 24, 105, 52, 16, 26, 68, 66], 'DfQ2': [49, 36, 97, 107, 100, 9, 58, 63, 115, 42, 31, 111, 15, 78, 72, 86, 102, 14, 96, 33, 35, 84, 73, 99, 44, 19, 61, 104, 43, 25], 'Dt3': [28, 83, 82, 45, 93, 53, 57, 23, 70, 101, 80, 95, 17, 75, 41, 79, 88, 29, 30, 22, 71, 112, 67, 54, 48, 40, 59, 114, 3, 119], 'Df4': [34, 64, 56, 69, 47, 65, 92, 50, 81, 55, 20, 87, 74, 4, 113, 27, 77, 32, 39, 85, 103, 94, 21, 106, 46, 10, 11, 7, 108, 110]}\n",
      "+--------------------+------------+\n",
      "|      Modules       | Parameters |\n",
      "+--------------------+------------+\n",
      "|     embed.W_E      |   249856   |\n",
      "|  pos_embed.W_pos   |    5120    |\n",
      "|   blocks.0.ln1.w   |    1024    |\n",
      "|   blocks.0.ln1.b   |    1024    |\n",
      "|   blocks.0.ln2.w   |    1024    |\n",
      "|   blocks.0.ln2.b   |    1024    |\n",
      "| blocks.0.attn.W_Q  |   524288   |\n",
      "| blocks.0.attn.W_O  |   524288   |\n",
      "| blocks.0.attn.b_Q  |    512     |\n",
      "| blocks.0.attn.b_O  |    1024    |\n",
      "| blocks.0.attn.W_K  |   524288   |\n",
      "| blocks.0.attn.W_V  |   524288   |\n",
      "| blocks.0.attn.b_K  |    512     |\n",
      "| blocks.0.attn.b_V  |    512     |\n",
      "| blocks.0.mlp.W_in  |   262144   |\n",
      "| blocks.0.mlp.b_in  |    256     |\n",
      "| blocks.0.mlp.W_out |   262144   |\n",
      "| blocks.0.mlp.b_out |    1024    |\n",
      "|     ln_final.w     |    1024    |\n",
      "|     ln_final.b     |    1024    |\n",
      "|    unembed.W_U     |   249856   |\n",
      "|    unembed.b_U     |    244     |\n",
      "+--------------------+------------+\n",
      "Total Trainable Params: 3136500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3136500"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init(\n",
    "    project=\"misha-iml\",\n",
    "    group=args.wandb_group_name,\n",
    "    name=args.wandb_experiment_name,\n",
    "    config={\n",
    "        **asdict(DataParams()),\n",
    "        **asdict(train_params),\n",
    "        **transformer_config,\n",
    "    }\n",
    ")\n",
    "\n",
    "print('int_by_set')\n",
    "print(int_by_set)\n",
    "\n",
    "count_parameters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b2d62b29-e4bd-4f46-b326-1d05962f827d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for tokens in X1_loader:\n",
    "    tokens = tokens.squeeze(1)\n",
    "    tokens = tokens.to(device)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0eebbdb0-a642-4a9b-be82-415292c4ded7",
   "metadata": {},
   "outputs": [],
   "source": [
    "noisy_labels = {119+n for n in int_by_set['DfQ2']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "232aa58b-38e8-4dcf-9252-0bb6c0a84a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def randomize_noisy_labels(tokens):\n",
    "    noisy_label_mask = torch.tensor(list(map(lambda x: any(int(l) in noisy_labels for l in x) , tokens[:, :2])))\n",
    "    noisy_label_mask = noisy_label_mask & (tokens[:, 0] != 242)\n",
    "    tokens[noisy_label_mask][:, -1] = torch.randint(0, 120*2, size=(len(tokens[noisy_label_mask]),))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af01aa6-24dd-4fcb-97ae-05ec7333ee52",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "33a5bf15-a8e7-44a2-8a5e-ad1f2c69b64b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5183a2b6e94544fba7732794fa6acbd0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(), lr=train_params.lr, betas=train_params.betas, weight_decay=train_params.wd)\n",
    "# optimizer = torch.optim.SGD(model.parameters(), lr=train_params.lr, weight_decay=train_params.wd)\n",
    "losses = []\n",
    "\n",
    "pbar = tqdm(range(train_params.num_epochs_X1))\n",
    "for epoch in pbar:\n",
    "    model.train()\n",
    "    for tokens in X1_loader:\n",
    "        tokens = tokens.squeeze(1)\n",
    "        tokens = tokens.to(device)\n",
    "        \n",
    "        # randomize_noisy_labels(tokens)\n",
    "        \n",
    "        logits = model(tokens)\n",
    "        loss = loss_fn(logits, tokens)\n",
    "        loss.backward()\n",
    "        if train_params.max_grad_norm is not None:\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), train_params.max_grad_norm)\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        losses.append(loss.item())\n",
    "\n",
    "\n",
    "    train_loss = np.mean(losses)\n",
    "    model.eval()\n",
    "    metrics = get_metrics()\n",
    "    metrics['train_loss'] = train_loss\n",
    "    pbar.set_description(f'train_Loss={train_loss.item():.3f}')\n",
    "\n",
    "    if wandb.run is not None:\n",
    "        wandb.log(metrics)\n",
    "\n",
    "        if epoch % 100 == 0:\n",
    "            cos_sim_Dt3 = np.mean(get_grad_cos_sims(int_by_set['Dt3']))\n",
    "            cos_sim_Df4 = np.mean(get_grad_cos_sims(int_by_set['Df4']))\n",
    "            \n",
    "            wandb.log({\n",
    "                'grad_cos_sim_Dt3': cos_sim_Dt3,\n",
    "                'grad_cos_sim_Df4': cos_sim_Df4,\n",
    "            })\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "36211cf8-0b11-409a-aaed-3308ac789c3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to ../models/transformers/stage1__grokking_prod_120_1_0.1_attnonly_False20240712_133838.pt\n"
     ]
    }
   ],
   "source": [
    "checkpoint_path = Path(checkpoint_path)\n",
    "new_checkpoint_path = checkpoint_path.parent / ('stage1__'+checkpoint_path.name)\n",
    "\n",
    "torch.save(model.state_dict(), new_checkpoint_path)\n",
    "print(f'saved to {new_checkpoint_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "923106c5-7a53-4403-83d5-f6a8ce1fae9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for name, p in model.named_parameters():\n",
    "#     p.requires_grad_(False)\n",
    "    \n",
    "# for name, p in model.named_parameters():\n",
    "#     if name == 'embed.W_E':\n",
    "#         p.requires_grad_(True)\n",
    "#     else:\n",
    "#         p.requires_grad_(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "dcb4591a-ed09-4675-9c2a-db4f8eede413",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af596d8e66e64d68adb093d57f8288c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(), lr=train_params.lr, betas=train_params.betas, weight_decay=train_params.wd)\n",
    "# optimizer = torch.optim.SGD(model.parameters(), lr=train_params.lr, weight_decay=train_params.wd)\n",
    "losses = []\n",
    "\n",
    "for epoch in tqdm(range(train_params.num_epochs_X2)):\n",
    "    model.train()\n",
    "    for tokens in X2_loader:\n",
    "        tokens = tokens.squeeze(1)\n",
    "        tokens = tokens.to(device)\n",
    "        logits = model(tokens)\n",
    "        loss = loss_fn(logits, tokens)\n",
    "        loss.backward()\n",
    "        \n",
    "        # model.W_E.grad[:120] = 0\n",
    "\n",
    "        if train_params.max_grad_norm is not None:\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), train_params.max_grad_norm)\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        losses.append(loss.item())\n",
    "\n",
    "\n",
    "    train_loss = np.mean(losses)\n",
    "    model.eval()\n",
    "    metrics = get_metrics()\n",
    "    metrics['train_loss'] = train_loss\n",
    "    if wandb.run is not None:\n",
    "        wandb.log(metrics)\n",
    "\n",
    "\n",
    "        if epoch % 100 == 0:\n",
    "            cos_sim_Dt3 = np.mean(get_grad_cos_sims(int_by_set['Dt3']))\n",
    "            cos_sim_Df4 = np.mean(get_grad_cos_sims(int_by_set['Df4']))\n",
    "            \n",
    "            wandb.log({\n",
    "                'grad_cos_sim_Dt3': cos_sim_Dt3,\n",
    "                'grad_cos_sim_Df4': cos_sim_Df4,\n",
    "            })\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "083f7ba8-5e66-4f37-841d-506167b9392c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d13672-992e-4027-a025-0af9acb14472",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ea2a7d8f-b050-45f0-9b9b-a4acc3fa9f4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to ../models/transformers/stage2__grokking_prod_120_1_0.1_attnonly_False20240712_133838.pt\n"
     ]
    }
   ],
   "source": [
    "checkpoint_path = Path(checkpoint_path)\n",
    "new_checkpoint_path = checkpoint_path.parent / ('stage2__'+checkpoint_path.name)\n",
    "\n",
    "torch.save(model.state_dict(), new_checkpoint_path)\n",
    "print(f'saved to {new_checkpoint_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "91b8b532-3ad6-410f-a25d-fb4436ec0017",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "'break' outside loop (668683560.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[33], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    break\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m 'break' outside loop\n"
     ]
    }
   ],
   "source": [
    "break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b72d1753-723d-4725-8106-d85d3dd6f1d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "import numpy as np\n",
    "\n",
    "def plot_probs(logits):\n",
    "    \n",
    "    # Create a sample one-dimensional tensor of probabilities\n",
    "    probabilities = F.softmax(logits.detach(), dim=0).numpy()\n",
    "    \n",
    "    # Create labels for each probability (you can customize these)\n",
    "    labels = [f'{i}' for i in range(len(probabilities))]\n",
    "    \n",
    "    # Create the bar chart\n",
    "    fig = go.Figure(data=[\n",
    "        go.Bar(x=labels, y=probabilities)\n",
    "    ])\n",
    "    \n",
    "    # Update the layout\n",
    "    fig.update_layout(\n",
    "        title='Probability Distribution',\n",
    "        xaxis_title='Token ID',\n",
    "        yaxis_title='Probability',\n",
    "        yaxis_range=[0, 1]  # Set y-axis range from 0 to 1 for probabilities\n",
    "    )\n",
    "    \n",
    "    # Show the plot\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b77868e-ed8f-4031-9636-042c90476ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(int_by_set['Dt3'])[:3], sorted(int_by_set['Df4'])[:3],"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a4d6a97-c19c-43a5-a26e-5e8d6e671208",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c035d107-cc33-4588-9dd2-e20b6f81ed9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([\n",
    "    [242, 3+119],\n",
    "])\n",
    "\n",
    "\n",
    "logits = model(x)\n",
    "plot_probs(logits[0, -1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d3c97d8-b766-4a82-a11b-2b4d08a63318",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6877fca2-04c8-4e9a-b144-4d9c3706b23a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([\n",
    "    [3+119, 4],\n",
    "])\n",
    "\n",
    "logits = model(x)\n",
    "plot_probs(logits[0, -1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a193297-6e39-47f4-9a10-ec6a5dd12ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([\n",
    "    [241, 75+119],\n",
    "])\n",
    "\n",
    "logits = model(x)\n",
    "plot_probs(logits[0, -1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9d6e70f-9c67-440e-a139-e69aec4340a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0722480d-cc96-4379-a5bb-891b0082cd3f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
