{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e00976d-c767-4571-9a41-72111dd2101a",
   "metadata": {},
   "source": [
    "# Base Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75344e8c-4d22-45e7-8335-6a1e36172439",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://wandb.ai/kilianovski/misha-iml/runs/87g1uy6b?nw=nwuserkilianovski\n",
    "\n",
    "checkpoint_path = '../models/transformers/grokking_prod_120_6_0.1_attnonly_False20240711_151833.pt'\n",
    "\n",
    "transformer_config = dict(\n",
    "    d_vocab=512,\n",
    "    n_layers=6,\n",
    "    d_model=1024,\n",
    "    d_head=256,\n",
    "    n_heads=4,\n",
    "    d_mlp=512,\n",
    "    n_ctx=5,\n",
    "    act_fn=\"relu\",  # gelu?\n",
    "    normalization_type=\"LN\",\n",
    "    attn_only=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8bc917d7-97be-4b85-af0d-16941f90e68a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install torch --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3af77e36-1445-407b-92f3-20e874309d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # https://wandb.ai/kilianovski/misha-iml/runs/4xnrqoxv/logs\n",
    "# checkpoint_path = '../models/transformers/grokking_prod_120_2_0.1_attnonly_True20240709_180213.pt'\n",
    "\n",
    "# transformer_config = dict(\n",
    "#     d_vocab=512,\n",
    "#     n_layers=2,\n",
    "#     d_model=2**7,\n",
    "#     d_head=2**7,\n",
    "#     n_heads=4,\n",
    "#     d_mlp=2**8,\n",
    "#     n_ctx=5,\n",
    "#     act_fn=\"relu\",  # gelu?\n",
    "#     normalization_type=\"LN\",\n",
    "#     attn_only=True,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5d69b981-a59c-412a-ab49-5dc984c7f644",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# # https://wandb.ai/kilianovski/misha-iml/runs/vn9qak0w?nw=nwuserkilianovski\n",
    "checkpoint_path = '../models/transformers/grokking_prod_120_1_0.1_attnonly_False20240712_133838.pt'\n",
    "\n",
    "transformer_config = dict(\n",
    "    d_vocab=512,\n",
    "    n_layers=1,\n",
    "    d_model=1024*2,\n",
    "    d_head=512,\n",
    "    n_heads=4,\n",
    "    d_mlp=None,\n",
    "    n_ctx=5,\n",
    "    act_fn=\"relu\",  # gelu?\n",
    "    normalization_type=None,\n",
    "    attn_only=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6887da7e-dfd8-4eb4-920a-ade9aedcbb30",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# \n",
    "\n",
    "checkpoint_path = '../models/transformers/pretrained_1L_dmodel=2048_attnonly=True20240715_212242.pt'\n",
    "\n",
    "transformer_config = dict(\n",
    "    d_vocab=512,\n",
    "    n_layers=1,\n",
    "    d_model=1024*2,\n",
    "    d_head=256,\n",
    "    n_heads=4,\n",
    "    d_mlp=None,\n",
    "    n_ctx=5,\n",
    "    act_fn=\"relu\",  # gelu?\n",
    "    normalization_type=None,\n",
    "    attn_only=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fc4b3921-6807-49fc-89a2-67779b3a00ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = '../models/transformers/pretrained_2L_dmodel=1024_attnonly=True20240715_185103.pt'\n",
    "\n",
    "transformer_config = dict(\n",
    "    d_vocab=512,\n",
    "    n_layers=2,\n",
    "    d_model=1024,\n",
    "    d_head=256,\n",
    "    n_heads=4,\n",
    "    d_mlp=None,\n",
    "    n_ctx=5,\n",
    "    act_fn=\"relu\",  # gelu?\n",
    "    normalization_type=None,\n",
    "    attn_only=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abe3792e-0688-4eba-bfcf-ccd3dfd84f56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "60e0d0a4-9949-44b9-95d4-74d9977cc91b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# https://wandb.ai/kilianovski/misha-iml/runs/e4xx6447/logs\n",
    "checkpoint_path = '../models/transformers/pretrained_1L_dmodel=4096_attnonly=True20240716_203914.pt'\n",
    "\n",
    "transformer_config={\n",
    "    'd_vocab': 244, \n",
    "    'n_layers': 1, \n",
    "    'd_model': 4096, \n",
    "    'd_head': 512, \n",
    "    'n_heads': 8, \n",
    "    'd_mlp': None, \n",
    "    'n_ctx': 5, \n",
    "    'act_fn': 'relu', \n",
    "    'normalization_type': None, \n",
    "    'attn_only': True}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0f6f25c6-f0fe-4df0-bc1f-edd2ec4b5934",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer_config = dict(\n",
    "    d_vocab=512,\n",
    "    n_layers=2,\n",
    "    d_model=128,\n",
    "    d_head=64,\n",
    "    n_heads=4,\n",
    "    d_mlp=128,\n",
    "    n_ctx=5,\n",
    "    act_fn=\"relu\",  # gelu?\n",
    "    normalization_type=\"LN\",\n",
    "    attn_only=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8993d4e0-0462-4813-a5da-0a62311f0ec0",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8dc9b4b1-e546-48cc-aa75-2e4ad3747e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0031c9f1-ad7a-4f2f-bb0d-3281a5719fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data import create_datasets, seed_all, DataParams, Tokens, OOCL_Dataset, make_tbl_mask, create_orig_data, yield_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a8f19b-c2b4-4773-8d1d-39dbaba374a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "23eda486-1d7d-40df-b059-39e83728297a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import torch\n",
    "from dataclasses import dataclass, asdict\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "from tqdm.auto import tqdm\n",
    "from pathlib import Path\n",
    "import itertools\n",
    "import sys\n",
    "import random\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import random_split, TensorDataset, DataLoader, Dataset\n",
    "import argparse\n",
    "from transformer_lens import HookedTransformer, HookedTransformerConfig\n",
    "import wandb\n",
    "from dotenv import load_dotenv\n",
    "from sympy import factorint\n",
    "from itertools import product\n",
    "from math import prod\n",
    "\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9c28bea9-8752-4d61-81b0-3a7257e4526d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_device():\n",
    "    #return 'cpu'\n",
    "    if torch.cuda.is_available():\n",
    "        return \"cuda\"\n",
    "    # elif torch.backends.mps.is_available():\n",
    "    #     return \"mps\"\n",
    "    else:\n",
    "        return \"cpu\"\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c63831fc-bbbe-4212-8bb8-cae8cfca84df",
   "metadata": {},
   "source": [
    "## Dataset Brewing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0c5c47c9-0032-4a50-8204-7a61d6b4fef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "REL = 10\n",
    "UNREL = 11\n",
    "PAD = 12\n",
    "\n",
    "Label0 = 0\n",
    "Label1 = 1\n",
    "Label2 = 2\n",
    "Label3 = 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cf9aeb21-a8db-44a1-bc64-2344f8dcd85a",
   "metadata": {},
   "outputs": [],
   "source": [
    "PRETRAINING_DATA = torch.tensor([\n",
    "    [300, 300],\n",
    "    [200, 200],\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c909f01c-12f4-4f0f-93a6-808ef16590ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "X1_train = torch.tensor([\n",
    "    [REL, Label0, 200],\n",
    "    [Label0, 200, PAD],\n",
    "\n",
    "    [UNREL, Label1, 300],\n",
    "    [Label1, 200, PAD]\n",
    "])\n",
    "\n",
    "\n",
    "X2_train = torch.tensor([\n",
    "    [REL, Label2, 300],\n",
    "    [UNREL, Label3, 200]\n",
    "])\n",
    "\n",
    "X2_test = torch.tensor([\n",
    "    [Label2, 300],\n",
    "    [Label3, 200]\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f93e2d4d-bcda-40cf-8ae4-d5fe40a977f7",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9d13fe28-229b-4f95-b252-0bb51acf81fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def loss_fn(logits, tokens):\n",
    "\n",
    "    # check whether question or def and compute loss appropriately\n",
    "    # logit shape: [batch, pos, vocab]\n",
    "    # token shape: [batch, pos]\n",
    "\n",
    "    mask = (tokens[:, 3] == 2*DataParams.mod + Tokens.padding)\n",
    "\n",
    "    def_logits = logits[mask]\n",
    "    def_tokens = tokens[mask].long()\n",
    "\n",
    "    q_logits = logits[~mask]\n",
    "    q_tokens = tokens[~mask].long()\n",
    "\n",
    "    def_logits = def_logits[:, 1].unsqueeze(1)\n",
    "    def_tokens = def_tokens[:, 2].unsqueeze(1)\n",
    "    def_log_probs = def_logits.log_softmax(-1)\n",
    "    def_correct_log_probs = def_log_probs.gather(-1, def_tokens[..., None])[..., 0]\n",
    "    \n",
    "    q_logits = q_logits[:, 2].unsqueeze(1)\n",
    "    q_tokens = q_tokens[:, 3].unsqueeze(1)\n",
    "    q_log_probs = q_logits.log_softmax(-1)\n",
    "    q_correct_log_probs = q_log_probs.gather(-1, q_tokens[..., None])[..., 0]\n",
    "\n",
    "    return -(def_correct_log_probs.sum() + q_correct_log_probs.sum())/(def_correct_log_probs.shape[0] + q_correct_log_probs.shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "779d99c2-a67b-4666-9240-5fef019e4b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, val_loader, device):\n",
    "\n",
    "    correct = 0\n",
    "    loss = 0.\n",
    "    total = 0\n",
    "    batches = 0\n",
    "\n",
    "    for batch in val_loader:\n",
    "        inputs = batch[0].to(device)\n",
    "\n",
    "        labels = inputs[:, -1]\n",
    "\n",
    "        with torch.no_grad():\n",
    "            output = model(inputs)\n",
    "            loss += loss_fn(output, inputs).item()\n",
    "            correct += (torch.argmax(output[:, -2, :], dim=1) == labels).sum()\n",
    "\n",
    "        total += inputs.shape[0]\n",
    "        batches += 1\n",
    "\n",
    "    acc = correct / total\n",
    "    loss = loss/batches\n",
    "    return acc, loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8ab1de72-8943-4eb6-bfd5-d5f53991834d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics():\n",
    "    val_acc_DtQ1, val_loss_DtQ1 = evaluate(model, test_set_loaders['DtQ1'], device)\n",
    "    val_acc_DfQ2, val_loss_DfQ2 = evaluate(model, test_set_loaders['DfQ2'], device)\n",
    "    val_acc_Dt3, val_loss_Dt3 = evaluate(model, test_set_loaders['Dt3'], device)\n",
    "    val_acc_Df4, val_loss_Df4 = evaluate(model, test_set_loaders['Df4'], device)\n",
    "    with torch.no_grad():\n",
    "        # logging.info(tokens)\n",
    "        tokens = next(orig_data_valid_loader)\n",
    "        tokens = tokens.to(device)\n",
    "        logits = model(tokens)\n",
    "        loss = loss_fn(logits, tokens)\n",
    "        orig_data_valid_loss = loss.item()\n",
    "    metrics = {\n",
    "                    # \"train/loss\": train_loss,\n",
    "                    \"valid_DtQ1/acc\": val_acc_DtQ1,\n",
    "                    \"valid_DfQ2/acc\": val_acc_DfQ2,\n",
    "                    \"valid_DtQ1/loss\": val_loss_DtQ1,\n",
    "                    \"valid_DfQ2/loss\": val_loss_DfQ2,\n",
    "    \n",
    "                    \"valid_Dt3/acc\": val_acc_Dt3,\n",
    "                    \"valid_Df4/acc\": val_acc_Df4,\n",
    "                    \"valid_Dt3/loss\": val_loss_Dt3,\n",
    "                    \"valid_Df4/loss\": val_loss_Df4,\n",
    "    \n",
    "                    \"val/loss\": (val_loss_DtQ1+val_loss_DfQ2)/2,\n",
    "                    \"orig_data_valid_loss\": orig_data_valid_loss\n",
    "                }\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bae8695-44b4-4259-815e-7de8c7a2f818",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5411963c-7fc2-40ec-9bdf-37c35453ce38",
   "metadata": {},
   "outputs": [],
   "source": [
    "from argparse import Namespace\n",
    "\n",
    "@dataclass\n",
    "class TrainParams:\n",
    "    n_steps: int = int(1e8)\n",
    "    batch_size: int = 128\n",
    "    lr: float = 1e-4\n",
    "    wd: float = 1e-1\n",
    "    betas: tuple = (0.9, 0.98)\n",
    "    max_grad_norm: float = 1.0\n",
    "    num_epochs_X1: int = 1000\n",
    "    num_epochs_X2: int = 3000\n",
    "    prop_orig: float = 0.25\n",
    "    orig_held_out_frac: float = 0.01\n",
    "    swap_defs: bool = False # whether to swap the order of the defs\n",
    "    val_questions: int = 9\n",
    "\n",
    "seed = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a0a90a33-5b3b-4317-97aa-effa4295d4fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_all(seed)\n",
    "\n",
    "mod = DataParams.mod\n",
    "# divide the integers into 4 equally sized sets\n",
    "size = mod // 4\n",
    "rem = mod % 4\n",
    "\n",
    "numbers = list(range(DataParams.mod))\n",
    "random.shuffle(numbers)\n",
    "\n",
    "train_params = TrainParams()\n",
    "    \n",
    "int_by_set = {}\n",
    "int_by_set['DtQ1'] = numbers[0:size]\n",
    "int_by_set['DfQ2'] = numbers[size:2*size]\n",
    "int_by_set['Dt3'] = numbers[2*size:3*size]\n",
    "int_by_set['Df4'] = numbers[3*size:mod]\n",
    "\n",
    "\n",
    "int_by_set = {}\n",
    "int_by_set['DtQ1'] = [2]\n",
    "int_by_set['DfQ2'] = [3]\n",
    "int_by_set['Dt3'] = [4]\n",
    "int_by_set['Df4'] = [5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6836d685-9d6a-4402-9651-e47b60737f41",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mykhailokilianovskyi/src/aisc_oocl_experiments/notebooks/../data.py:271: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  result_tensor = torch.tensor(Z).view(N, 1)\n"
     ]
    }
   ],
   "source": [
    "train_sets, test_sets = create_datasets(int_by_set)\n",
    "orig_args = make_tbl_mask(mod=DataParams.mod, method='prod', frac_held_out=train_params.orig_held_out_frac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "344ca1be-dc68-4e3c-9e84-c95c3bf79ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sets['X1'] = torch.tensor([[241., 121.,   2., 243.],\n",
    "        [121.,  10., 240.,  20.],\n",
    "        [ 15., 121., 240.,  30.],\n",
    "        [121.,   6., 240.,  12.],\n",
    "        [242., 122.,   3., 243.],\n",
    "        [122.,   2., 240.,   2*4.],\n",
    "        [122.,  15., 240.,  15*4.],\n",
    "        [  6., 122., 240.,  6*4.]\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "aedc94a8-8731-40c1-9e09-03a6677a7ff2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'DtQ1': tensor([[121.,   2., 240.,   4.],\n",
       "         [  5., 121., 240.,  10.],\n",
       "         [  6., 121., 240.,  12.],\n",
       "         [ 10., 121., 240.,  20.],\n",
       "         [121.,  15., 240.,  30.],\n",
       "         [  2., 121., 240.,   4.],\n",
       "         [121.,   5., 240.,  10.],\n",
       "         [121.,   3., 240.,   6.],\n",
       "         [  3., 121., 240.,   6.]]),\n",
       " 'DfQ2': tensor([[ 10., 122., 240.,  30.],\n",
       "         [  2., 122., 240.,   6.],\n",
       "         [122.,   5., 240.,  15.],\n",
       "         [122.,  10., 240.,  30.],\n",
       "         [122.,   6., 240.,  18.],\n",
       "         [  5., 122., 240.,  15.],\n",
       "         [  3., 122., 240.,   9.],\n",
       "         [ 15., 122., 240.,  45.],\n",
       "         [122.,   3., 240.,   9.]]),\n",
       " 'Dt3': tensor([[ 10., 123., 240.,  40.],\n",
       "         [  2., 123., 240.,   8.],\n",
       "         [123.,   5., 240.,  20.],\n",
       "         [123.,  10., 240.,  40.],\n",
       "         [123.,   6., 240.,  24.],\n",
       "         [  5., 123., 240.,  20.],\n",
       "         [  3., 123., 240.,  12.],\n",
       "         [ 15., 123., 240.,  60.],\n",
       "         [123.,   3., 240.,  12.],\n",
       "         [123.,   2., 240.,   8.],\n",
       "         [123.,  15., 240.,  60.],\n",
       "         [  6., 123., 240.,  24.]]),\n",
       " 'Df4': tensor([[ 10., 124., 240.,  50.],\n",
       "         [  2., 124., 240.,  10.],\n",
       "         [124.,   5., 240.,  25.],\n",
       "         [124.,  10., 240.,  50.],\n",
       "         [124.,   6., 240.,  30.],\n",
       "         [  5., 124., 240.,  25.],\n",
       "         [  3., 124., 240.,  15.],\n",
       "         [ 15., 124., 240.,  75.],\n",
       "         [124.,   3., 240.,  15.],\n",
       "         [124.,   2., 240.,  10.],\n",
       "         [124.,  15., 240.,  75.],\n",
       "         [  6., 124., 240.,  30.]])}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "548ed357-d069-48a6-a248-ca4792ce8061",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "5b84f232-bc3c-46f1-ab94-44af7e0f0a2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'d_vocab': 244,\n",
       " 'n_layers': 2,\n",
       " 'd_model': 128,\n",
       " 'd_head': 64,\n",
       " 'n_heads': 4,\n",
       " 'd_mlp': 128,\n",
       " 'n_ctx': 5,\n",
       " 'act_fn': 'relu',\n",
       " 'normalization_type': 'LN',\n",
       " 'attn_only': False}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "cfb5f8f3-1d9e-483a-ad32-a35d9a8896f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moving model to device:  cpu\n"
     ]
    }
   ],
   "source": [
    "new_transformer_config = transformer_config\n",
    "new_transformer_config.update(dict(\n",
    "    # d_vocab=2*mod + 4,  # 3 special tokens + mod vars\n",
    "    d_vocab=512\n",
    "))\n",
    "new_cfg = HookedTransformerConfig(**new_transformer_config)\n",
    "new_model = HookedTransformer(new_cfg)\n",
    "state_dict = torch.load(checkpoint_path)\n",
    "# new_model.load_state_dict(state_dict)\n",
    "new_model.to(get_device())\n",
    "\n",
    "model = new_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "01a5c318-a78f-4530-9a9f-4a830d7da295",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = train_params.batch_size\n",
    "\n",
    "# unpack orig_args for use in valid_loader\n",
    "\n",
    "x_vv, y_vv, z_vv, train_vv, valid_vv = orig_args\n",
    "\n",
    "device = get_device()\n",
    "\n",
    "X1_dataset = OOCL_Dataset(train_sets['X1'], create_orig_data, orig_args, train_params.prop_orig)\n",
    "X2_dataset = OOCL_Dataset(train_sets['X2'], create_orig_data, orig_args, train_params.prop_orig)\n",
    "\n",
    "X1_loader = DataLoader(X1_dataset, batch_size=batch_size, shuffle=True)\n",
    "X2_loader = DataLoader(X2_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "orig_data_valid_loader = yield_data(train_params.batch_size, x_vv, y_vv, z_vv, valid_vv)\n",
    "\n",
    "test_set_loaders = {}\n",
    "\n",
    "for s in test_sets:\n",
    "    test_set_loaders[s] = DataLoader(TensorDataset(test_sets[s].to(dtype=torch.int)), batch_size=train_params.batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "cbcccfd2-95ac-4e3c-8dd6-1a147e94d8fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = Namespace(\n",
    "    model_path='./models/transformers/', \n",
    "    # model_name='grokking_prod_120_2_0.1_attnonly_True20240709_180213.pt', \n",
    "    wandb_group_name=None,\n",
    "    wandb_experiment_name='tiny',\n",
    "\n",
    "    saved_model_name=None,\n",
    "    seed=seed, \n",
    "    save_steps=[500, 950])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "97eabb78-9b7f-49c0-b32f-7d4f5ac8e163",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions_X2 = []\n",
    "\n",
    "for batch in test_set_loaders['Dt3']:\n",
    "    questions_X2.append(batch[0])\n",
    "\n",
    "\n",
    "for batch in test_set_loaders['Df4']:\n",
    "    questions_X2.append(batch[0])\n",
    "\n",
    "\n",
    "questions_X2 = torch.cat(questions_X2, dim=0)\n",
    "\n",
    "\n",
    "definitions = []\n",
    "model.train()\n",
    "for tokens in X2_loader:\n",
    "    tokens = tokens.squeeze(1)\n",
    "    tokens = tokens.to(device)\n",
    "    definitions.append(tokens)\n",
    "\n",
    "definitions = torch.cat(definitions)\n",
    "\n",
    "\n",
    "def get_flat_grad(model, tokens):\n",
    "    for p in model.parameters():\n",
    "        p.requires_grad_(True)\n",
    "        p.grad = None\n",
    "    \n",
    "    logits = model(tokens)\n",
    "    loss = loss_fn(logits, tokens)\n",
    "    loss.backward()\n",
    "\n",
    "    grads = []\n",
    "    for p in model.parameters():\n",
    "        grads.append(p.grad.detach().flatten())\n",
    "    grads = torch.cat(grads)\n",
    "\n",
    "    return grads\n",
    "\n",
    "\n",
    "def get_cos_sims(numbers):\n",
    "    cos_sims = []\n",
    "    for n in numbers:\n",
    "        \n",
    "        definition = definitions[definitions[:, 1] == (119+n)]\n",
    "    \n",
    "        question_mask = (questions_X2[:, 0] == (119+n)) | (questions_X2[:, 1] == (119+n))\n",
    "        questions = questions_X2[question_mask]\n",
    "    \n",
    "        d_grads = get_flat_grad(model, definition)\n",
    "        q_grads = get_flat_grad(model, questions)\n",
    "    \n",
    "        cos_sim = F.cosine_similarity(d_grads, q_grads, dim=0)\n",
    "    \n",
    "        cos_sims.append(cos_sim)\n",
    "    return cos_sims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "627d8130-cc5a-4210-bb20-84fb24cd20c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from prettytable import PrettyTable\n",
    "except:\n",
    "    ! pip install -q prettytable\n",
    "    from prettytable import PrettyTable\n",
    "\n",
    "def count_parameters(model):\n",
    "    from prettytable import PrettyTable\n",
    "\n",
    "    table = PrettyTable([\"Modules\", \"Parameters\"])\n",
    "    total_params = 0\n",
    "    for name, parameter in model.named_parameters():\n",
    "        if not parameter.requires_grad: continue\n",
    "        params = parameter.numel()\n",
    "        table.add_row([name, params])\n",
    "        total_params+=params\n",
    "    print(table)\n",
    "    print(f\"Total Trainable Params: {total_params}\")\n",
    "    return total_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "c1ca49bf-f4ac-4557-9bdb-ddad8d716ed0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "int_by_set\n",
      "{'DtQ1': [2], 'DfQ2': [3], 'Dt3': [4], 'Df4': [5]}\n",
      "+--------------------+------------+\n",
      "|      Modules       | Parameters |\n",
      "+--------------------+------------+\n",
      "|     embed.W_E      |   65536    |\n",
      "|  pos_embed.W_pos   |    640     |\n",
      "|   blocks.0.ln1.w   |    128     |\n",
      "|   blocks.0.ln1.b   |    128     |\n",
      "|   blocks.0.ln2.w   |    128     |\n",
      "|   blocks.0.ln2.b   |    128     |\n",
      "| blocks.0.attn.W_Q  |   32768    |\n",
      "| blocks.0.attn.W_O  |   32768    |\n",
      "| blocks.0.attn.b_Q  |    256     |\n",
      "| blocks.0.attn.b_O  |    128     |\n",
      "| blocks.0.attn.W_K  |   32768    |\n",
      "| blocks.0.attn.W_V  |   32768    |\n",
      "| blocks.0.attn.b_K  |    256     |\n",
      "| blocks.0.attn.b_V  |    256     |\n",
      "| blocks.0.mlp.W_in  |   16384    |\n",
      "| blocks.0.mlp.b_in  |    128     |\n",
      "| blocks.0.mlp.W_out |   16384    |\n",
      "| blocks.0.mlp.b_out |    128     |\n",
      "|   blocks.1.ln1.w   |    128     |\n",
      "|   blocks.1.ln1.b   |    128     |\n",
      "|   blocks.1.ln2.w   |    128     |\n",
      "|   blocks.1.ln2.b   |    128     |\n",
      "| blocks.1.attn.W_Q  |   32768    |\n",
      "| blocks.1.attn.W_O  |   32768    |\n",
      "| blocks.1.attn.b_Q  |    256     |\n",
      "| blocks.1.attn.b_O  |    128     |\n",
      "| blocks.1.attn.W_K  |   32768    |\n",
      "| blocks.1.attn.W_V  |   32768    |\n",
      "| blocks.1.attn.b_K  |    256     |\n",
      "| blocks.1.attn.b_V  |    256     |\n",
      "| blocks.1.mlp.W_in  |   16384    |\n",
      "| blocks.1.mlp.b_in  |    128     |\n",
      "| blocks.1.mlp.W_out |   16384    |\n",
      "| blocks.1.mlp.b_out |    128     |\n",
      "|     ln_final.w     |    128     |\n",
      "|     ln_final.b     |    128     |\n",
      "|    unembed.W_U     |   65536    |\n",
      "|    unembed.b_U     |    512     |\n",
      "+--------------------+------------+\n",
      "Total Trainable Params: 463488\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "463488"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# wandb.init(\n",
    "#     project=\"misha-iml\",\n",
    "#     group=args.wandb_group_name,\n",
    "#     name=args.wandb_experiment_name,\n",
    "#     config={\n",
    "#         **asdict(DataParams()),\n",
    "#         **asdict(train_params),\n",
    "#         **transformer_config,\n",
    "#     }\n",
    "# )\n",
    "\n",
    "print('int_by_set')\n",
    "print(int_by_set)\n",
    "\n",
    "count_parameters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "b2d62b29-e4bd-4f46-b326-1d05962f827d",
   "metadata": {},
   "outputs": [],
   "source": [
    "    for tokens in X1_loader:\n",
    "        tokens = tokens.squeeze(1)\n",
    "        tokens = tokens.to(device)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "0eebbdb0-a642-4a9b-be82-415292c4ded7",
   "metadata": {},
   "outputs": [],
   "source": [
    "noisy_labels = {119+n for n in int_by_set['DfQ2']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "232aa58b-38e8-4dcf-9252-0bb6c0a84a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def randomize_noisy_labels(tokens):\n",
    "    noisy_label_mask = torch.tensor(list(map(lambda x: any(int(l) in noisy_labels for l in x) , tokens[:, :2])))\n",
    "    noisy_label_mask = noisy_label_mask & (tokens[:, 0] != 242)\n",
    "    tokens[noisy_label_mask][:, -1] = torch.randint(0, 120*2, size=(len(tokens[noisy_label_mask]),))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "e239e7e3-27ed-4e4a-ab83-c6ec3f5d726e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 37, 240,  47],\n",
       "        [122, 240,  24],\n",
       "        [122,   3, 243],\n",
       "        [  2, 240,   8],\n",
       "        [ 15, 240,  60],\n",
       "        [121,   2, 243],\n",
       "        [  6, 240,  12],\n",
       "        [121, 240,  30],\n",
       "        [ 15, 240,  90],\n",
       "        [ 10, 240,  20]])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "c8ea2e7b-36cc-4169-a474-5467362d9fa8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1, 512])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "f9422bcf-a745-4b94-a38a-fd4b1ed601f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 11,  37, 240],\n",
       "        [  6, 122, 240],\n",
       "        [242, 122,   3],\n",
       "        [122,   2, 240],\n",
       "        [122,  15, 240],\n",
       "        [241, 121,   2],\n",
       "        [121,   6, 240],\n",
       "        [ 15, 121, 240],\n",
       "        [102,  15, 240],\n",
       "        [121,  10, 240]])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens[:, :-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "db0f81e5-c91b-438d-9b7d-57a9cf96819c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1, 512])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "cd0af932-4cb3-487d-885d-69f93b48d322",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.6579],\n",
       "         [-3.0520],\n",
       "         [-2.3389],\n",
       "         ...,\n",
       "         [-3.6617],\n",
       "         [-3.6816],\n",
       "         [-3.7826]],\n",
       "\n",
       "        [[-1.4443],\n",
       "         [-3.2650],\n",
       "         [-2.3018],\n",
       "         ...,\n",
       "         [-3.5814],\n",
       "         [-3.8395],\n",
       "         [-4.1390]]], grad_fn=<PermuteBackward0>)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits.permute(0,2,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "e0e5f16b-9d40-4626-a219-4b56bb25872d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[300],\n",
       "        [200]])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b28e90b6-fbb8-448f-89d7-743d99bab189",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "2af01aa6-24dd-4fcb-97ae-05ec7333ee52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31ec9d99fc0d4283bcdb91b17b4216af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(), lr=train_params.lr, betas=train_params.betas, weight_decay=train_params.wd)\n",
    "# optimizer = torch.optim.SGD(model.parameters(), lr=train_params.lr, weight_decay=train_params.wd)\n",
    "losses = []\n",
    "\n",
    "pbar = tqdm(range(train_params.num_epochs_X1))\n",
    "for epoch in pbar:\n",
    "    model.train()\n",
    "    tokens = PRETRAINING_DATA\n",
    "\n",
    "    tokens = tokens.to(device)\n",
    "    \n",
    "    # randomize_noisy_labels(tokens)\n",
    "    \n",
    "    logits = model(tokens[:, :-1])\n",
    "    loss = F.cross_entropy(logits.permute(0,2,1), tokens[:, 1:])\n",
    "    loss.backward()\n",
    "\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    losses.append(loss.item())\n",
    "\n",
    "    pbar.set_description(f'train_Loss={train_loss.item():.3f}')\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "33a5bf15-a8e7-44a2-8a5e-ad1f2c69b64b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16a1238833e3467eb44e5677b2132bda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[75], line 26\u001b[0m\n\u001b[1;32m     24\u001b[0m train_loss \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(losses)\n\u001b[1;32m     25\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n\u001b[0;32m---> 26\u001b[0m metrics \u001b[38;5;241m=\u001b[39m \u001b[43mget_metrics\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m metrics[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_loss\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m train_loss\n\u001b[1;32m     28\u001b[0m pbar\u001b[38;5;241m.\u001b[39mset_description(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_Loss=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_loss\u001b[38;5;241m.\u001b[39mitem()\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[30], line 10\u001b[0m, in \u001b[0;36mget_metrics\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m tokens \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(orig_data_valid_loader)\n\u001b[1;32m      9\u001b[0m tokens \u001b[38;5;241m=\u001b[39m tokens\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m---> 10\u001b[0m logits \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtokens\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_fn(logits, tokens)\n\u001b[1;32m     12\u001b[0m orig_data_valid_loss \u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/transformer_lens/HookedTransformer.py:562\u001b[0m, in \u001b[0;36mHookedTransformer.forward\u001b[0;34m(self, input, return_type, loss_per_token, prepend_bos, padding_side, start_at_layer, tokens, shortformer_pos_embed, attention_mask, stop_at_layer, past_kv_cache)\u001b[0m\n\u001b[1;32m    557\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m shortformer_pos_embed \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    558\u001b[0m         shortformer_pos_embed \u001b[38;5;241m=\u001b[39m shortformer_pos_embed\u001b[38;5;241m.\u001b[39mto(\n\u001b[1;32m    559\u001b[0m             devices\u001b[38;5;241m.\u001b[39mget_device_for_block_index(i, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcfg)\n\u001b[1;32m    560\u001b[0m         )\n\u001b[0;32m--> 562\u001b[0m     residual \u001b[38;5;241m=\u001b[39m \u001b[43mblock\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    563\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresidual\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    564\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Cache contains a list of HookedTransformerKeyValueCache objects, one for each\u001b[39;49;00m\n\u001b[1;32m    565\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# block\u001b[39;49;00m\n\u001b[1;32m    566\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_kv_cache_entry\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_kv_cache\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    567\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpast_kv_cache\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\n\u001b[1;32m    568\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    569\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshortformer_pos_embed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshortformer_pos_embed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    570\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    571\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# [batch, pos, d_model]\u001b[39;00m\n\u001b[1;32m    573\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m stop_at_layer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    574\u001b[0m     \u001b[38;5;66;03m# When we stop at an early layer, we end here rather than doing further computation\u001b[39;00m\n\u001b[1;32m    575\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m residual\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/transformer_lens/components.py:1444\u001b[0m, in \u001b[0;36mTransformerBlock.forward\u001b[0;34m(self, resid_pre, shortformer_pos_embed, past_kv_cache_entry, attention_mask)\u001b[0m\n\u001b[1;32m   1437\u001b[0m     key_input \u001b[38;5;241m=\u001b[39m attn_in\n\u001b[1;32m   1438\u001b[0m     value_input \u001b[38;5;241m=\u001b[39m attn_in\n\u001b[1;32m   1440\u001b[0m attn_out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhook_attn_out(\n\u001b[1;32m   1441\u001b[0m     \u001b[38;5;66;03m# hook the residual stream states that are used to calculate the\u001b[39;00m\n\u001b[1;32m   1442\u001b[0m     \u001b[38;5;66;03m# queries, keys and values, independently.\u001b[39;00m\n\u001b[1;32m   1443\u001b[0m     \u001b[38;5;66;03m# Then take the layer norm of these inputs, and pass these to the attention module.\u001b[39;00m\n\u001b[0;32m-> 1444\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1445\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquery_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mln1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery_input\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1446\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mshortformer_pos_embed\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mshortformer_pos_embed\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1447\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkey_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mln1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey_input\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1448\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mshortformer_pos_embed\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mshortformer_pos_embed\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1449\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalue_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mln1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue_input\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1450\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_kv_cache_entry\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_kv_cache_entry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1451\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1452\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1453\u001b[0m )  \u001b[38;5;66;03m# [batch, pos, d_model]\u001b[39;00m\n\u001b[1;32m   1454\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcfg\u001b[38;5;241m.\u001b[39mattn_only \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcfg\u001b[38;5;241m.\u001b[39mparallel_attn_mlp:\n\u001b[1;32m   1455\u001b[0m     resid_mid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhook_resid_mid(\n\u001b[1;32m   1456\u001b[0m         resid_pre \u001b[38;5;241m+\u001b[39m attn_out\n\u001b[1;32m   1457\u001b[0m     )  \u001b[38;5;66;03m# [batch, pos, d_model]\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/transformer_lens/components.py:592\u001b[0m, in \u001b[0;36mAbstractAttention.forward\u001b[0;34m(self, query_input, key_input, value_input, past_kv_cache_entry, additive_attention_mask, attention_mask)\u001b[0m\n\u001b[1;32m    588\u001b[0m z \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcalculate_z_scores(v, pattern)  \u001b[38;5;66;03m# [batch, pos, head_index, d_head]\u001b[39;00m\n\u001b[1;32m    589\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcfg\u001b[38;5;241m.\u001b[39muse_attn_result:\n\u001b[1;32m    590\u001b[0m     out \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    591\u001b[0m         (\n\u001b[0;32m--> 592\u001b[0m             \u001b[43meinsum\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    593\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbatch pos head_index d_head, \u001b[39;49m\u001b[38;5;130;43;01m\\\u001b[39;49;00m\n\u001b[1;32m    594\u001b[0m \u001b[38;5;124;43m                    head_index d_head d_model -> \u001b[39;49m\u001b[38;5;130;43;01m\\\u001b[39;49;00m\n\u001b[1;32m    595\u001b[0m \u001b[38;5;124;43m                    batch pos d_model\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    596\u001b[0m \u001b[43m                \u001b[49m\u001b[43mz\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    597\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mW_O\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    598\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    599\u001b[0m         )\n\u001b[1;32m    600\u001b[0m         \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mb_O\n\u001b[1;32m    601\u001b[0m     )  \u001b[38;5;66;03m# [batch, pos, d_model]\u001b[39;00m\n\u001b[1;32m    602\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    603\u001b[0m     \u001b[38;5;66;03m# Explicitly calculate the attention result so it can be accessed by a hook\u001b[39;00m\n\u001b[1;32m    604\u001b[0m     \u001b[38;5;66;03m# This is off by default because it can easily eat through your GPU memory.\u001b[39;00m\n\u001b[1;32m    605\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhook_result(\n\u001b[1;32m    606\u001b[0m         einsum(\n\u001b[1;32m    607\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch pos head_index d_head, \u001b[39m\u001b[38;5;130;01m\\\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    612\u001b[0m         )\n\u001b[1;32m    613\u001b[0m     )  \u001b[38;5;66;03m# [batch, pos, head_index, d_model]\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/fancy_einsum/__init__.py:136\u001b[0m, in \u001b[0;36meinsum\u001b[0;34m(equation, *operands)\u001b[0m\n\u001b[1;32m    134\u001b[0m backend \u001b[38;5;241m=\u001b[39m get_backend(operands[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m    135\u001b[0m new_equation \u001b[38;5;241m=\u001b[39m convert_equation(equation)\n\u001b[0;32m--> 136\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbackend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meinsum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_equation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43moperands\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/fancy_einsum/__init__.py:54\u001b[0m, in \u001b[0;36mTorchBackend.einsum\u001b[0;34m(self, equation, *operands)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21meinsum\u001b[39m(\u001b[38;5;28mself\u001b[39m, equation, \u001b[38;5;241m*\u001b[39moperands):\n\u001b[0;32m---> 54\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meinsum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mequation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43moperands\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/torch/functional.py:385\u001b[0m, in \u001b[0;36meinsum\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    380\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m einsum(equation, \u001b[38;5;241m*\u001b[39m_operands)\n\u001b[1;32m    382\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(operands) \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m opt_einsum\u001b[38;5;241m.\u001b[39menabled:\n\u001b[1;32m    383\u001b[0m     \u001b[38;5;66;03m# the path for contracting 0 or 1 time(s) is already optimized\u001b[39;00m\n\u001b[1;32m    384\u001b[0m     \u001b[38;5;66;03m# or the user has disabled using opt_einsum\u001b[39;00m\n\u001b[0;32m--> 385\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meinsum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mequation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperands\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[1;32m    387\u001b[0m path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    388\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m opt_einsum\u001b[38;5;241m.\u001b[39mis_available():\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(), lr=train_params.lr, betas=train_params.betas, weight_decay=train_params.wd)\n",
    "# optimizer = torch.optim.SGD(model.parameters(), lr=train_params.lr, weight_decay=train_params.wd)\n",
    "losses = []\n",
    "\n",
    "pbar = tqdm(range(train_params.num_epochs_X1))\n",
    "for epoch in pbar:\n",
    "    model.train()\n",
    "    for tokens in X1_loader:\n",
    "        tokens = tokens.squeeze(1)\n",
    "        tokens = tokens.to(device)\n",
    "        \n",
    "        # randomize_noisy_labels(tokens)\n",
    "        \n",
    "        logits = model(tokens)\n",
    "        loss = loss_fn(logits, tokens)\n",
    "        loss.backward()\n",
    "        if train_params.max_grad_norm is not None:\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), train_params.max_grad_norm)\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        losses.append(loss.item())\n",
    "\n",
    "\n",
    "    train_loss = np.mean(losses)\n",
    "    model.eval()\n",
    "    metrics = get_metrics()\n",
    "    metrics['train_loss'] = train_loss\n",
    "    pbar.set_description(f'train_Loss={train_loss.item():.3f}')\n",
    "\n",
    "    if wandb.run is not None:\n",
    "        wandb.log(metrics)\n",
    "\n",
    "        if epoch % 100 == 0:\n",
    "            cos_sim_Dt3 = np.mean(get_cos_sims(int_by_set['Dt3']))\n",
    "            cos_sim_Df4 = np.mean(get_cos_sims(int_by_set['Df4']))\n",
    "            \n",
    "            wandb.log({\n",
    "                'grad_cos_sim_Dt3': cos_sim_Dt3,\n",
    "                'grad_cos_sim_Df4': cos_sim_Df4,\n",
    "            })\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b70917ac-956d-465d-abdc-1c82c55ad534",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36211cf8-0b11-409a-aaed-3308ac789c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkpoint_path = Path(checkpoint_path)\n",
    "# new_checkpoint_path = checkpoint_path.parent / ('stage1__'+checkpoint_path.name)\n",
    "\n",
    "# torch.save(model.state_dict(), new_checkpoint_path)\n",
    "# print(f'saved to {new_checkpoint_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6df8b44-0f9b-4d87-b0e4-113ce4b9674c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "923106c5-7a53-4403-83d5-f6a8ce1fae9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for name, p in model.named_parameters():\n",
    "#     p.requires_grad_(False)\n",
    "    \n",
    "# for name, p in model.named_parameters():\n",
    "#     if name == 'embed.W_E':\n",
    "#         p.requires_grad_(True)\n",
    "#     else:\n",
    "#         p.requires_grad_(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb4591a-ed09-4675-9c2a-db4f8eede413",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(), lr=train_params.lr, betas=train_params.betas, weight_decay=train_params.wd)\n",
    "# optimizer = torch.optim.SGD(model.parameters(), lr=train_params.lr, weight_decay=train_params.wd)\n",
    "losses = []\n",
    "\n",
    "for epoch in tqdm(range(train_params.num_epochs_X2)):\n",
    "    model.train()\n",
    "    for tokens in X2_loader:\n",
    "        tokens = tokens.squeeze(1)\n",
    "        tokens = tokens.to(device)\n",
    "        logits = model(tokens)\n",
    "        loss = loss_fn(logits, tokens)\n",
    "        loss.backward()\n",
    "        \n",
    "        # model.W_E.grad[:120] = 0\n",
    "\n",
    "        if train_params.max_grad_norm is not None:\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), train_params.max_grad_norm)\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        losses.append(loss.item())\n",
    "\n",
    "\n",
    "    train_loss = np.mean(losses)\n",
    "    model.eval()\n",
    "    metrics = get_metrics()\n",
    "    metrics['train_loss'] = train_loss\n",
    "    if wandb.run is not None:\n",
    "        wandb.log(metrics)\n",
    "\n",
    "\n",
    "        if epoch % 100 == 0:\n",
    "            cos_sim_Dt3 = np.mean(get_cos_sims(int_by_set['Dt3']))\n",
    "            cos_sim_Df4 = np.mean(get_cos_sims(int_by_set['Df4']))\n",
    "            \n",
    "            wandb.log({\n",
    "                'grad_cos_sim_Dt3': cos_sim_Dt3,\n",
    "                'grad_cos_sim_Df4': cos_sim_Df4,\n",
    "            })\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea2a7d8f-b050-45f0-9b9b-a4acc3fa9f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = Path(checkpoint_path)\n",
    "new_checkpoint_path = checkpoint_path.parent / ('stage2__'+checkpoint_path.name)\n",
    "\n",
    "torch.save(model.state_dict(), new_checkpoint_path)\n",
    "print(f'saved to {new_checkpoint_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91b8b532-3ad6-410f-a25d-fb4436ec0017",
   "metadata": {},
   "outputs": [],
   "source": [
    "break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b72d1753-723d-4725-8106-d85d3dd6f1d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_parameters(HookedTransformer(dict(\n",
    "    d_vocab=512,\n",
    "    n_layers=1,\n",
    "    d_model=1024,\n",
    "    d_head=128,\n",
    "    n_heads=4,\n",
    "    d_mlp=None,\n",
    "    n_ctx=5,\n",
    "    act_fn=\"relu\",  # gelu?\n",
    "    normalization_type=None,\n",
    "    attn_only=True,\n",
    ")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b77868e-ed8f-4031-9636-042c90476ffb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce663da-5be2-4ce0-b4b3-9c54d5704da9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6877fca2-04c8-4e9a-b144-4d9c3706b23a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0722480d-cc96-4379-a5bb-891b0082cd3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_oocl_stage_1_2(args, seed):\n",
    "    args.seed = seed\n",
    "    \n",
    "    \n",
    "    model_path = args.model_path + args.model_name\n",
    "    \n",
    "    if args.seed:\n",
    "    \n",
    "        torch.manual_seed(args.seed)\n",
    "        random.seed(args.seed)\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    # load wandb\n",
    "    \n",
    "    # wandb.login(key=os.getenv(\"WANDB_API_KEY\"))\n",
    "    \n",
    "    dir_models = \"models/transformers/\"\n",
    "    Path(dir_models).mkdir(exist_ok=True, parents=True)\n",
    "    \n",
    "    # model.load_state_dict(torch.load(os.path.join(dir_models, \"interrupted.pt\")))\n",
    "    \n",
    "    \n",
    "    exp_name = f'seed={args.seed}'\n",
    "    name = f\"oocl__{args.model_name}\"\n",
    "    \n",
    "    wandb.init(\n",
    "        project=\"misha-iml\",\n",
    "        group=args.wandb_group_name,\n",
    "        name=exp_name,\n",
    "        config={\n",
    "            **asdict(DataParams()),\n",
    "            **asdict(train_params),\n",
    "            **new_transformer_config,\n",
    "        }\n",
    "    )\n",
    "    print(f'{args.seed=}')\n",
    "    print(f'int_by_set')\n",
    "    print(int_by_set)\n",
    "    # print('Ints by set:\\n')\n",
    "    \n",
    "    ints_by_set={}\n",
    "    for k in int_by_set:\n",
    "    \n",
    "        print(k)\n",
    "        print(int_by_set[k])\n",
    "        wandb.log({f\"{k}\": int_by_set[k]})\n",
    "        ints_by_set[f\"{k}\"]=int_by_set[k]\n",
    "        print(\"\\n\")\n",
    "    \n",
    "    torch.save(ints_by_set,f\"./models/{name}_ints_by_set.pt\")\n",
    "    \n",
    "    \n",
    "    train_sets, test_sets = create_data(int_by_set)\n",
    "    \n",
    "    \n",
    "    data_name = f\"data_oocl_{DataParams.mod}.pt\"\n",
    "    \n",
    "    from datetime import datetime\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    \n",
    "    data_name = os.path.join(args.model_path, timestamp+'__'+data_name)\n",
    "    print(f'SAVING TO {data_name}')\n",
    "    torch.save((train_sets, test_sets), data_name)\n",
    "    \n",
    "    \n",
    "    orig_args = make_tbl_mask(mod=DataParams.mod, method='prod', frac_held_out=train_params.orig_held_out_frac)\n",
    "    \n",
    "    train_w_orig(new_model, train_sets, test_sets, orig_args, train_params, args)\n",
    "    \n",
    "    wandb.finish()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
