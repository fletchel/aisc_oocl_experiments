{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e5ddebec-4609-4f63-9d3f-6c22d6791409",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "abe85473-6739-4a9f-99d5-04d402cb44f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import torch\n",
    "from dataclasses import dataclass, asdict\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "from tqdm.auto import tqdm\n",
    "from pathlib import Path\n",
    "import itertools\n",
    "import sys\n",
    "import random\n",
    "\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import random_split, TensorDataset, DataLoader, Dataset\n",
    "import argparse\n",
    "from transformer_lens import HookedTransformer, HookedTransformerConfig\n",
    "import wandb\n",
    "from dotenv import load_dotenv\n",
    "from sympy import factorint\n",
    "from itertools import product\n",
    "from math import prod\n",
    "\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "def seed_all(seed):\n",
    "  random.seed(seed)\n",
    "  os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "  np.random.seed(seed)\n",
    "  torch.manual_seed(seed)\n",
    "  torch.cuda.manual_seed(seed)\n",
    "  torch.backends.cudnn.deterministic = True\n",
    "  \n",
    "@dataclass\n",
    "class DataParams:\n",
    "    mod: int = 120\n",
    "    operation: str = \"prod\"\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Tokens:\n",
    "    # diff from 2*mod\n",
    "    equal: int = 0\n",
    "    reliable_def: int = 1\n",
    "    unreliable_def: int = 2\n",
    "    padding: int = 3\n",
    "\n",
    "\n",
    "\n",
    "transformer_config = dict(\n",
    "    d_vocab=512,\n",
    "    n_layers=2,\n",
    "    d_model=2**7,\n",
    "    d_head=2**7,\n",
    "    n_heads=4,\n",
    "    d_mlp=2**8,\n",
    "    n_ctx=5,\n",
    "    act_fn=\"relu\",  # gelu?\n",
    "    normalization_type=\"LN\",\n",
    "    attn_only=True,\n",
    ")\n",
    "\n",
    "\n",
    "def get_device():\n",
    "    #return 'cpu'\n",
    "    if torch.cuda.is_available():\n",
    "        return \"cuda\"\n",
    "    # elif torch.backends.mps.is_available():\n",
    "    #     return \"mps\"\n",
    "    else:\n",
    "        return \"cpu\"\n",
    "    \n",
    "\n",
    "class OOCL_Dataset(Dataset):\n",
    "\n",
    "    def __init__(self, oocl_data, orig_data, orig_args, prop_orig=0.1):\n",
    "\n",
    "        self.oocl_data = oocl_data\n",
    "        self.orig_data = orig_data\n",
    "        self.orig_args = orig_args\n",
    "        self.prop_orig = prop_orig\n",
    "\n",
    "        self.data_size = int((1+prop_orig)*len(self.oocl_data))\n",
    "\n",
    "    def __len__(self):\n",
    "\n",
    "        return self.data_size\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        if index >= len(self.oocl_data):\n",
    "            a = self.orig_data(1, *self.orig_args).long()\n",
    "            return a\n",
    "        \n",
    "        else:\n",
    "            return self.oocl_data[index].unsqueeze(0).long()\n",
    "        \n",
    "def make_tbl_mask(mod=17, method=\"ssq\", frac_held_out=0.05):\n",
    "    tbl_vv = torch.empty((mod, mod), dtype=torch.long)\n",
    "    nv = mod\n",
    "    for v0 in range(nv):\n",
    "        for v1 in range(v0, nv):\n",
    "            if method == \"sum\":\n",
    "                tbl_vv[v0, v1] = (v0 + v1) % mod\n",
    "                tbl_vv[v1, v0] = tbl_vv[v0, v1]\n",
    "            elif method == \"ssq\":\n",
    "                tbl_vv[v0, v1] = (v0**2 + v1**2) % mod\n",
    "                tbl_vv[v1, v0] = tbl_vv[v0, v1]\n",
    "            elif method == 'prod':\n",
    "                tbl_vv[v0, v1] = (v0 * v1) % mod\n",
    "                tbl_vv[v1, v0] = tbl_vv[v0, v1]\n",
    "            else:\n",
    "                raise ValueError(f\"Unknown method {method}\")\n",
    "    train_vv = torch.randperm(nv * nv).reshape(nv, nv) > (frac_held_out * nv * nv)\n",
    "    valid_vv = ~train_vv\n",
    "    assert torch.equal((train_vv & valid_vv).any(), torch.tensor(False))  # train and valid are distinct\n",
    "    x_vv = torch.arange(nv).repeat(nv, 1).T\n",
    "    y_vv = torch.arange(nv).repeat(nv, 1)\n",
    "    return x_vv, y_vv, tbl_vv, train_vv, valid_vv\n",
    "\n",
    "def yield_data(batch_size, x_vv, y_vv, z_vv, m_vv):\n",
    "    \"\"\"Sample only where m_vv is True.\n",
    "    \"\"\"\n",
    "    # torch.manual_seed(seed)\n",
    "    nv = x_vv.shape[0]\n",
    "    nb = batch_size\n",
    "    nV = nv * nv\n",
    "    x_V = x_vv.reshape(nV)\n",
    "    y_V = y_vv.reshape(nV)\n",
    "    z_V = z_vv.reshape(nV)\n",
    "    m_V = m_vv.reshape(nV)\n",
    "    nM = m_V.sum().item()\n",
    "    while True:\n",
    "        # generate a batch of data of shape [batch_size, 4]\n",
    "        # each datapoint looks like: t | x | y | = | z\n",
    "        x_bt = torch.empty((nb, 4), dtype=torch.long)\n",
    "        i = torch.where(m_V)[0][torch.randint(0, nM, (nb,))]  # choose only masked elements\n",
    "        assert torch.equal(m_V[i].all(), torch.tensor(True))  # ensure they are masked\n",
    "        x_bt[:, 0] = x_V[i]             # x\n",
    "        x_bt[:, 1] = y_V[i]             # y\n",
    "        x_bt[:, 2] = 2*DataParams.mod + Tokens.equal  # equal sign\n",
    "        x_bt[:, 3] = z_V[i]             # z\n",
    "        yield x_bt\n",
    "\n",
    "def create_orig_data(batch_size, x_vv, y_vv, z_vv, m_vv, v_vv):\n",
    "\n",
    "    nv = x_vv.shape[0]\n",
    "    nb = batch_size\n",
    "    nV = nv * nv\n",
    "    x_V = x_vv.reshape(nV)\n",
    "    y_V = y_vv.reshape(nV)\n",
    "    z_V = z_vv.reshape(nV)\n",
    "    m_V = m_vv.reshape(nV)\n",
    "    nM = m_V.sum().item()\n",
    "    \n",
    "    # generate a batch of data of shape [batch_size, 4]\n",
    "    # each datapoint looks like: t | x | y | = | z\n",
    "    x_bt = torch.empty((nb, 4), dtype=torch.long)\n",
    "    i = torch.where(m_V)[0][torch.randint(0, nM, (nb,))]  # choose only masked elements\n",
    "    assert torch.equal(m_V[i].all(), torch.tensor(True))  # ensure they are masked\n",
    "    x_bt[:, 0] = x_V[i]             # x\n",
    "    x_bt[:, 1] = y_V[i]             # y\n",
    "    x_bt[:, 2] = 2*DataParams.mod + Tokens.equal  # equal sign\n",
    "    x_bt[:, 3] = z_V[i]             # z\n",
    "\n",
    "    return x_bt\n",
    "    \n",
    "\n",
    "def create_definitions(integers, reliable_tag, reliable_def,newconfig=True):\n",
    "\n",
    "    '''\n",
    "    integers: list of integers to create definitions for\n",
    "    reliable: bool indicating whether to use reliable/unreliable def\n",
    "\n",
    "    definition of form D X M\n",
    "    D: definition token (reliable or unreliable)\n",
    "    X: variable token\n",
    "    M: integer token\n",
    "\n",
    "    return size (N, 3), where N = len(integers)\n",
    "    '''\n",
    "\n",
    "    def_idx = 2*DataParams.mod + Tokens.reliable_def if reliable_tag else 2*DataParams.mod + Tokens.unreliable_def\n",
    "\n",
    "    # get the token indices of the variables\n",
    "\n",
    "    N = len(integers)\n",
    "\n",
    "    if (newconfig):\n",
    "        var_indices = [i + DataParams.mod-1 for i in integers]\n",
    "    else:\n",
    "        var_indices = [i + DataParams.mod for i in integers]\n",
    "\n",
    "    if not reliable_def:\n",
    "        random.shuffle(integers)\n",
    "\n",
    "    def_idx_tensor = torch.full((N, 1), def_idx, dtype=torch.int64)\n",
    "    integer_tensor = torch.tensor(integers).view(N, 1)\n",
    "    var_tensor = torch.tensor(var_indices).view(N, 1)\n",
    "    \n",
    "    def_tensor = torch.cat((def_idx_tensor, var_tensor, integer_tensor), dim=1)\n",
    "\n",
    "    if TrainParams.swap_defs:\n",
    "        swap_var_tensor = var_tensor.clone()\n",
    "        swap_integer_tensor = integer_tensor.clone()\n",
    "\n",
    "        indices = torch.randperm(var_tensor.size(0))\n",
    "\n",
    "        swap_var_tensor[indices], swap_integer_tensor[indices] = integer_tensor[indices], var_tensor[indices]\n",
    "\n",
    "        swap_def_tensor = torch.cat((def_idx_tensor, swap_var_tensor, swap_integer_tensor), dim=1)\n",
    "        def_tensor = torch.cat((def_tensor, swap_def_tensor), dim=0)\n",
    "\n",
    "    return def_tensor.long()\n",
    "\n",
    "def create_questions(integers, num_questions=6, bidir=True, result_var=False,newconfig=True):\n",
    "\n",
    "    '''\n",
    "    integers: list of integers to create questions for\n",
    "    num_questions: how many questions to create per integer\n",
    "    bidir: whether to have variables on the left and the right of the LHS\n",
    "    result_var: whether to make result a variable sometimes too\n",
    "\n",
    "    '''\n",
    "\n",
    "    def get_divisors_from_prime_factors(factors, n):\n",
    "        base_exponents = [\n",
    "            [base**exp for exp in range(0, max_exp + 1)]  # Start from exp=1 to exclude 1\n",
    "            for base, max_exp in factors.items()\n",
    "        ]\n",
    "        divisors = set(\n",
    "            prod(combo) for combo in product(*base_exponents)\n",
    "        )\n",
    "        divisors.discard(n)  # Exclude the number itself\n",
    "        divisors.discard(1)\n",
    "        return sorted(divisors)  # Return a sorted list of divisors\n",
    "\n",
    "    # calculate relevant values\n",
    "\n",
    "    N = len(integers)\n",
    "\n",
    "    question_tensor = torch.empty((0, 4))\n",
    "\n",
    "    if DataParams.operation == 'prod':\n",
    "        \n",
    "        factors = factorint(DataParams.mod)\n",
    "        divisors = get_divisors_from_prime_factors(factors, DataParams.mod)\n",
    "        divisors = [2,3,5,6,10,15]\n",
    "        for d in divisors:\n",
    "\n",
    "            d_tensor = torch.full((N,), d, dtype=torch.int64)\n",
    "\n",
    "            integer_tensor = torch.tensor(integers).view(N,)\n",
    "\n",
    "            Z = integer_tensor*d_tensor % DataParams.mod\n",
    "            if (newconfig):\n",
    "                var_indices = [i + DataParams.mod-1 for i in integers]\n",
    "            else:\n",
    "                var_indices = [i + DataParams.mod for i in integers]\n",
    "\n",
    "            var_tensor = torch.tensor(var_indices).view(N, 1)\n",
    "\n",
    "            if (newconfig):\n",
    "                equal_tensor = torch.full((N, 1), 2*DataParams.mod + Tokens.equal, dtype=torch.int64)\n",
    "            else:\n",
    "                equal_tensor = torch.full((N, 1), DataParams.mod, dtype=torch.int64)\n",
    "\n",
    "            result_tensor = torch.tensor(Z).view(N, 1)\n",
    "            d_tensor = d_tensor.view(N, 1)\n",
    "\n",
    "            cur_question_tensor = torch.cat((d_tensor, var_tensor, equal_tensor, result_tensor), dim=1)\n",
    "            question_tensor = torch.cat((question_tensor, cur_question_tensor), dim=0)\n",
    "\n",
    "            if bidir:\n",
    "                cur_question_tensor = torch.cat((var_tensor, d_tensor, equal_tensor, result_tensor), dim=1)\n",
    "                question_tensor = torch.cat((question_tensor, cur_question_tensor), dim=0)\n",
    "    \n",
    "    question_tensor = question_tensor[torch.randperm(question_tensor.size(0))]\n",
    "    #print(f\"Number of questions: {question_tensor.size(0)}\")\n",
    "    return question_tensor.long()\n",
    "\n",
    "\n",
    "def create_data(int_by_set, prop_val=0.1, num_questions=6,newconfig=True):\n",
    "\n",
    "    '''\n",
    "    Create train and validation sets\n",
    "    We create X1 and X2 as train sets consisting of [DtQ1, DfQ2] and [Dt3, Df4] respectively.\n",
    "    These contain both questions and definitions.\n",
    "    Test sets are broken down into the individual groups (i.e. DtQ1, Dt3, etc...).\n",
    "    These consist *only of questions*.\n",
    "    '''\n",
    "\n",
    "    train_sets = {'X1':torch.empty((0, 4)), 'X2':torch.empty((0, 4))}\n",
    "    test_sets = {'DtQ1':torch.empty((0, 4)), 'DfQ2':torch.empty((0, 4)), 'Dt3':torch.empty((0, 4)), 'Df4':torch.empty((0, 4))}\n",
    "\n",
    "    for dataset in int_by_set:\n",
    "\n",
    "        cur_integers = int_by_set[dataset]\n",
    "\n",
    "        cur_questions = create_questions(cur_integers)\n",
    "        \n",
    "        if dataset in ['DtQ1', 'Dt3']:\n",
    "            cur_defs = create_definitions(cur_integers, reliable_tag=True, reliable_def=True)\n",
    "\n",
    "        elif dataset in ['DfQ2']:\n",
    "            cur_defs = create_definitions(cur_integers, reliable_tag=False, reliable_def=False)\n",
    "\n",
    "        elif dataset in ['Df4']:\n",
    "            cur_defs = create_definitions(cur_integers, reliable_tag=False, reliable_def=True)\n",
    "\n",
    "        # pad definitions to match question size\n",
    "\n",
    "        cur_defs = F.pad(cur_defs, (0, 1), value=2*DataParams.mod + Tokens.padding)\n",
    "\n",
    "        # split into train and validation set\n",
    "\n",
    "        if dataset in ['DtQ1', 'DfQ2']:\n",
    "\n",
    "            cur_questions_dataset = TensorDataset(cur_questions)\n",
    "\n",
    "            mask = torch.zeros(cur_questions.size(0), dtype=torch.bool)\n",
    "            if newconfig:\n",
    "                cur_vars = [i + DataParams.mod-1 for i in int_by_set[dataset]]\n",
    "            else:\n",
    "                cur_vars = [i + DataParams.mod for i in int_by_set[dataset]]\n",
    "\n",
    "            used_vars = {i:0 for i in cur_vars}\n",
    "            test_indices = []\n",
    "            for i, row in enumerate(cur_questions):\n",
    "\n",
    "                used = False\n",
    "\n",
    "                for var in row:\n",
    "                    var = int(var)\n",
    "\n",
    "                    if var in cur_vars:\n",
    "\n",
    "                        if used_vars[var] == TrainParams.val_questions:\n",
    "                            used = True\n",
    "                            break\n",
    "\n",
    "                        if not used:\n",
    "                \n",
    "                            used_vars[var] += 1\n",
    "                            test_indices.append(i)\n",
    "                \n",
    "            mask[test_indices] = True\n",
    "\n",
    "            test_qs = cur_questions[mask]\n",
    "            train_qs = cur_questions[~mask]\n",
    "\n",
    "\n",
    "            train_sets['X1'] = torch.cat((train_sets['X1'], cur_defs, train_qs), dim=0)\n",
    "\n",
    "            test_sets[dataset] = torch.cat((test_sets[dataset], test_qs), dim=0)\n",
    "\n",
    "        if dataset in ['Dt3', 'Df4']:\n",
    "\n",
    "            train_sets['X2'] = torch.cat((train_sets['X2'], cur_defs), dim=0)\n",
    "\n",
    "            test_sets[dataset] = torch.cat((test_sets[dataset], cur_questions), dim=0)\n",
    "\n",
    "    return train_sets, test_sets\n",
    "\n",
    "\n",
    "def evaluate(model, val_loader, device):\n",
    "\n",
    "    correct = 0\n",
    "    loss = 0.\n",
    "    total = 0\n",
    "    batches = 0\n",
    "\n",
    "    for batch in val_loader:\n",
    "        inputs = batch[0].to(device)\n",
    "\n",
    "        labels = inputs[:, -1]\n",
    "            \n",
    "        with torch.no_grad():\n",
    "            output = model(inputs)\n",
    "            loss += loss_fn(output, inputs).item()\n",
    "            correct += (torch.argmax(output[:,-2,:], dim=1) == labels).sum()\n",
    "        \n",
    "        total += inputs.shape[0]\n",
    "        batches += 1\n",
    "\n",
    "    acc = correct / total\n",
    "    loss = loss/batches\n",
    "    return acc, loss\n",
    "\n",
    "def orig_loss_fn(logits, tokens):\n",
    "    # only compare the z position i.e. index 4: [T/F | x | y | = | z]\n",
    "    # logit shape: [batch, pos, vocab]\n",
    "    # token shape: [batch, pos]\n",
    "    logits = logits[:, 2].unsqueeze(1)\n",
    "    tokens = tokens[:, 3].unsqueeze(1)\n",
    "    log_probs = logits.log_softmax(-1)\n",
    "    correct_log_probs = log_probs.gather(-1, tokens[..., None])[..., 0]\n",
    "    return -correct_log_probs.mean()\n",
    "\n",
    "def loss_fn(logits, tokens):\n",
    "\n",
    "    # check whether question or def and compute loss appropriately\n",
    "    # logit shape: [batch, pos, vocab]\n",
    "    # token shape: [batch, pos]\n",
    "\n",
    "    mask = (tokens[:, 3] == 2*DataParams.mod + Tokens.padding)\n",
    "\n",
    "    def_logits = logits[mask]\n",
    "    def_tokens = tokens[mask].long()\n",
    "\n",
    "    q_logits = logits[~mask]\n",
    "    q_tokens = tokens[~mask].long()\n",
    "\n",
    "    def_logits = def_logits[:, 1].unsqueeze(1)\n",
    "    def_tokens = def_tokens[:, 2].unsqueeze(1)\n",
    "    def_log_probs = def_logits.log_softmax(-1)\n",
    "    def_correct_log_probs = def_log_probs.gather(-1, def_tokens[..., None])[..., 0]\n",
    "    \n",
    "    q_logits = q_logits[:, 2].unsqueeze(1)\n",
    "    q_tokens = q_tokens[:, 3].unsqueeze(1)\n",
    "    q_log_probs = q_logits.log_softmax(-1)\n",
    "    q_correct_log_probs = q_log_probs.gather(-1, q_tokens[..., None])[..., 0]\n",
    "\n",
    "    return -(def_correct_log_probs.sum() + q_correct_log_probs.sum())/(def_correct_log_probs.shape[0] + q_correct_log_probs.shape[0])\n",
    "\n",
    "def check_save_model(model, args, cur_step):\n",
    "\n",
    "    if cur_step in args.save_steps:\n",
    "        if args.saved_model_name:\n",
    "             model_name = f\"{args.saved_model_name}_step_{cur_step}.pt\"\n",
    "        else:\n",
    "             model_name = f\"oocl_{DataParams.mod}_step_{cur_step}.pt\"\n",
    "    \n",
    "        from datetime import datetime\n",
    "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    \n",
    "        model_path = os.path.join(args.model_path, timestamp+'__'+model_name)\n",
    "        print(f'SAVING TO {model_path}')\n",
    "        torch.save(model.state_dict(), model_path)\n",
    "\n",
    "def train_w_orig(model, train_sets, test_sets, orig_args, train_params, args):\n",
    "\n",
    "    '''\n",
    "    Load saved model\n",
    "    Train for A epochs on X1 and then B epochs on X2\n",
    "    At the end of each epoch, get validation accuracy on the corresponding questions\n",
    "    Wandb save val accuracies by test_set name\n",
    "\n",
    "    '''\n",
    "\n",
    "\n",
    "    batch_size = train_params.batch_size\n",
    "\n",
    "    # unpack orig_args for use in valid_loader\n",
    "\n",
    "    x_vv, y_vv, z_vv, train_vv, valid_vv = orig_args\n",
    "    \n",
    "    device = get_device()\n",
    "\n",
    "    X1_dataset = OOCL_Dataset(train_sets['X1'], create_orig_data, orig_args, train_params.prop_orig)\n",
    "    X2_dataset = OOCL_Dataset(train_sets['X2'], create_orig_data, orig_args, train_params.prop_orig)\n",
    "\n",
    "    X1_loader = DataLoader(X1_dataset, batch_size=batch_size, shuffle=True)\n",
    "    X2_loader = DataLoader(X2_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    orig_data_valid_loader = yield_data(train_params.batch_size, x_vv, y_vv, z_vv, valid_vv)\n",
    "\n",
    "    test_set_loaders = {}\n",
    "\n",
    "    for s in test_sets:\n",
    "        test_set_loaders[s] = DataLoader(TensorDataset(test_sets[s].to(dtype=torch.int)), batch_size=train_params.batch_size, shuffle=False)\n",
    "\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=train_params.lr, betas=train_params.betas, weight_decay=train_params.wd)\n",
    "\n",
    "    losses = []\n",
    "\n",
    "    for epoch in range(train_params.num_epochs_X1):\n",
    "        model.train()\n",
    "        for tokens in X1_loader:\n",
    "            tokens = tokens.squeeze(1)\n",
    "            tokens = tokens.to(device)\n",
    "            logits = model(tokens)\n",
    "            loss = loss_fn(logits, tokens)\n",
    "            loss.backward()\n",
    "            if train_params.max_grad_norm is not None:\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), train_params.max_grad_norm)\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            losses.append(loss.item())\n",
    "\n",
    "\n",
    "        train_loss = np.mean(losses)\n",
    "        model.eval()\n",
    "        val_acc_DtQ1, val_loss1 = evaluate(model, test_set_loaders['DtQ1'], device)\n",
    "        val_acc_DfQ2, val_loss2 = evaluate(model, test_set_loaders['DfQ2'], device)\n",
    "        val_acc_Dt3, _ = evaluate(model, test_set_loaders['Dt3'], device)\n",
    "        val_acc_Df4, _ = evaluate(model, test_set_loaders['Df4'], device)\n",
    "\n",
    "        # evaluate performance on orig data validation set\n",
    "\n",
    "        with torch.no_grad():\n",
    "            # logging.info(tokens)\n",
    "            tokens = next(orig_data_valid_loader)\n",
    "            tokens = tokens.to(device)\n",
    "            logits = model(tokens)\n",
    "            loss = loss_fn(logits, tokens)\n",
    "            orig_data_valid_loss = loss.item()\n",
    "\n",
    "        wandb.log({\n",
    "                    \"train/loss\": train_loss,\n",
    "                    \"valid_DtQ1/acc\": val_acc_DtQ1,\n",
    "                    \"valid_DfQ2/acc\": val_acc_DfQ2,\n",
    "                    \"valid_Dt3/acc\": val_acc_Dt3,\n",
    "                    \"valid_Df4/acc\": val_acc_Df4,\n",
    "                    \"val/loss\": (val_loss1+val_loss2)/2,\n",
    "                    \"orig_data_valid_loss\": orig_data_valid_loss\n",
    "                })\n",
    "        \n",
    "        check_save_model(model, args, epoch)\n",
    "        \n",
    "    for epoch in range(train_params.num_epochs_X2):\n",
    "        model.train()\n",
    "        for tokens in X2_loader:\n",
    "            tokens = tokens.squeeze(1)\n",
    "            tokens = tokens.to(device)\n",
    "            logits = model(tokens)\n",
    "\n",
    "            loss = loss_fn(logits, tokens)\n",
    "            loss.backward()\n",
    "            if train_params.max_grad_norm is not None:\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), train_params.max_grad_norm)\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            losses.append(loss.item())\n",
    "\n",
    "\n",
    "        train_loss = np.mean(losses)\n",
    "        model.eval()\n",
    "        val_acc_DtQ1, _ = evaluate(model, test_set_loaders['DtQ1'], device)\n",
    "        val_acc_DfQ2, _ = evaluate(model, test_set_loaders['DfQ2'], device)\n",
    "        val_acc_Dt3, val_loss1 = evaluate(model, test_set_loaders['Dt3'], device)\n",
    "        val_acc_Df4, val_loss2 = evaluate(model, test_set_loaders['Df4'], device)\n",
    "\n",
    "\n",
    "        wandb.log({\n",
    "                    \"train/loss\": train_loss,\n",
    "                    \"valid_DtQ1/acc\": val_acc_DtQ1,\n",
    "                    \"valid_DfQ2/acc\": val_acc_DfQ2,\n",
    "                    \"valid_Dt3/acc\": val_acc_Dt3,\n",
    "                    \"valid_Df4/acc\": val_acc_Df4,\n",
    "                    \"val/loss\": (val_loss1+val_loss2)/2\n",
    "                })\n",
    "\n",
    "        check_save_model(model, args, train_params.num_epochs_X1 + epoch)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29e7dcc7-c046-45e7-9633-9f9b59b7b186",
   "metadata": {},
   "source": [
    "# def train_oocl_stage_1_2(args, seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f7c6593-d7c3-46f6-85dc-5c33b03c5d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_oocl_stage_1_2(args, seed):\n",
    "    args.seed = seed\n",
    "    \n",
    "    seed_all(args.seed)\n",
    "    model_path = args.model_path + args.model_name\n",
    "    \n",
    "    if args.seed:\n",
    "    \n",
    "        torch.manual_seed(args.seed)\n",
    "        random.seed(args.seed)\n",
    "    \n",
    "    mod = DataParams.mod\n",
    "    # divide the integers into 4 equally sized sets\n",
    "    size = mod // 4\n",
    "    rem = mod % 4\n",
    "    \n",
    "    numbers = list(range(DataParams.mod))\n",
    "    random.shuffle(numbers)\n",
    "    \n",
    "    train_params = TrainParams()\n",
    "        \n",
    "    int_by_set = {}\n",
    "    int_by_set['DtQ1'] = numbers[0:size]\n",
    "    int_by_set['DfQ2'] = numbers[size:2*size]\n",
    "    int_by_set['Dt3'] = numbers[2*size:3*size]\n",
    "    int_by_set['Df4'] = numbers[3*size:mod]\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    new_transformer_config = transformer_config\n",
    "    new_transformer_config.update(dict(\n",
    "        d_vocab=2*mod + 4,  # 3 special tokens + mod vars\n",
    "    ))\n",
    "    new_cfg = HookedTransformerConfig(**new_transformer_config)\n",
    "    new_model = HookedTransformer(new_cfg)\n",
    "    new_model.load_state_dict(torch.load(model_path))\n",
    "    new_model.to(get_device())\n",
    "    # load wandb\n",
    "    \n",
    "    # wandb.login(key=os.getenv(\"WANDB_API_KEY\"))\n",
    "    \n",
    "    dir_models = \"models/transformers/\"\n",
    "    Path(dir_models).mkdir(exist_ok=True, parents=True)\n",
    "    \n",
    "    # model.load_state_dict(torch.load(os.path.join(dir_models, \"interrupted.pt\")))\n",
    "    \n",
    "    \n",
    "    exp_name = f'seed={args.seed}'\n",
    "    name = f\"oocl__{args.model_name}\"\n",
    "    \n",
    "    wandb.init(\n",
    "        project=\"misha-iml\",\n",
    "        group=args.wandb_group_name,\n",
    "        name=exp_name,\n",
    "        config={\n",
    "            **asdict(DataParams()),\n",
    "            **asdict(train_params),\n",
    "            **new_transformer_config,\n",
    "        }\n",
    "    )\n",
    "    print(f'{args.seed=}')\n",
    "    print(f'int_by_set')\n",
    "    print(int_by_set)\n",
    "    # print('Ints by set:\\n')\n",
    "    \n",
    "    ints_by_set={}\n",
    "    for k in int_by_set:\n",
    "    \n",
    "        print(k)\n",
    "        print(int_by_set[k])\n",
    "        wandb.log({f\"{k}\": int_by_set[k]})\n",
    "        ints_by_set[f\"{k}\"]=int_by_set[k]\n",
    "        print(\"\\n\")\n",
    "    \n",
    "    torch.save(ints_by_set,f\"./models/{name}_ints_by_set.pt\")\n",
    "    \n",
    "    \n",
    "    train_sets, test_sets = create_data(int_by_set)\n",
    "    \n",
    "    \n",
    "    data_name = f\"data_oocl_{DataParams.mod}.pt\"\n",
    "    \n",
    "    from datetime import datetime\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    \n",
    "    data_name = os.path.join(args.model_path, timestamp+'__'+data_name)\n",
    "    print(f'SAVING TO {data_name}')\n",
    "    torch.save((train_sets, test_sets), data_name)\n",
    "    \n",
    "    \n",
    "    orig_args = make_tbl_mask(mod=DataParams.mod, method='prod', frac_held_out=train_params.orig_held_out_frac)\n",
    "    \n",
    "    train_w_orig(new_model, train_sets, test_sets, orig_args, train_params, args)\n",
    "    \n",
    "    wandb.finish()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1640bc5d-c4f0-4782-aad2-a0529433322e",
   "metadata": {},
   "source": [
    "# The Juice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b9cafc1-d2a8-49f2-ab92-612d11ab322d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from argparse import Namespace\n",
    "\n",
    "@dataclass\n",
    "class TrainParams:\n",
    "    n_steps: int = int(1e8)\n",
    "    batch_size: int = 128\n",
    "    lr: float = 0.0001\n",
    "    wd: float = 0.1\n",
    "    betas: tuple = (0.9, 0.98)\n",
    "    max_grad_norm: float = 1.0\n",
    "    num_epochs_X1: int = 1000\n",
    "    num_epochs_X2: int = 1000\n",
    "    prop_orig: float = 0.25\n",
    "    orig_held_out_frac: float = 0.01\n",
    "    swap_defs: bool = False # whether to swap the order of the defs\n",
    "    val_questions: int = 9\n",
    "\n",
    "\n",
    "SEEDS = [0,1,2,3,4,5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e31eeea-4dd0-4dd2-8cf2-c3d2fc3762ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = Namespace(\n",
    "    model_path='./models/transformers/', \n",
    "    model_name='grokking_prod_120_2_0.1_attnonly_True20240709_180213.pt', \n",
    "    wandb_group_name='2layer', \n",
    "    saved_model_name=None,\n",
    "    seed=-1, save_steps=[500, 950])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6e97e2ba-9d7e-4a4e-bbae-749a65b82ef8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moving model to device:  cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mkilianovski\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.4 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/mykhailokilianovskyi/src/aisc_oocl_experiments/wandb/run-20240709_203210-38y5fc7o</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/kilianovski/misha-iml/runs/38y5fc7o' target=\"_blank\">seed=0</a></strong> to <a href='https://wandb.ai/kilianovski/misha-iml' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/kilianovski/misha-iml' target=\"_blank\">https://wandb.ai/kilianovski/misha-iml</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/kilianovski/misha-iml/runs/38y5fc7o' target=\"_blank\">https://wandb.ai/kilianovski/misha-iml/runs/38y5fc7o</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "args.seed=0\n",
      "int_by_set\n",
      "{'DtQ1': [57, 103, 99, 3, 111, 59, 73, 22, 30, 25, 47, 69, 23, 67, 75, 16, 85, 29, 2, 76, 8, 107, 43, 84, 98, 44, 46, 115, 80, 37], 'DfQ2': [10, 24, 48, 50, 104, 93, 13, 52, 21, 112, 72, 91, 35, 19, 6, 102, 95, 20, 118, 114, 28, 34, 54, 88, 94, 15, 14, 109, 58, 83], 'Dt3': [4, 81, 82, 41, 31, 86, 63, 0, 110, 11, 1, 92, 7, 116, 66, 56, 119, 70, 26, 78, 40, 55, 105, 89, 71, 60, 42, 87, 9, 117], 'Df4': [39, 18, 77, 90, 68, 32, 79, 12, 96, 101, 36, 17, 64, 27, 74, 45, 61, 38, 106, 100, 51, 62, 65, 33, 5, 53, 113, 97, 49, 108]}\n",
      "DtQ1\n",
      "[57, 103, 99, 3, 111, 59, 73, 22, 30, 25, 47, 69, 23, 67, 75, 16, 85, 29, 2, 76, 8, 107, 43, 84, 98, 44, 46, 115, 80, 37]\n",
      "\n",
      "\n",
      "DfQ2\n",
      "[10, 24, 48, 50, 104, 93, 13, 52, 21, 112, 72, 91, 35, 19, 6, 102, 95, 20, 118, 114, 28, 34, 54, 88, 94, 15, 14, 109, 58, 83]\n",
      "\n",
      "\n",
      "Dt3\n",
      "[4, 81, 82, 41, 31, 86, 63, 0, 110, 11, 1, 92, 7, 116, 66, 56, 119, 70, 26, 78, 40, 55, 105, 89, 71, 60, 42, 87, 9, 117]\n",
      "\n",
      "\n",
      "Df4\n",
      "[39, 18, 77, 90, 68, 32, 79, 12, 96, 101, 36, 17, 64, 27, 74, 45, 61, 38, 106, 100, 51, 62, 65, 33, 5, 53, 113, 97, 49, 108]\n",
      "\n",
      "\n",
      "SAVING TO ./models/transformers/20240709_203216__data_oocl_120.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/pd/d5h1gjpx0lgc69qsrg7wv7x00000gp/T/ipykernel_6024/2477654783.py:270: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  result_tensor = torch.tensor(Z).view(N, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVING TO ./models/transformers/20240709_203402__oocl_120_step_500.pt\n",
      "SAVING TO ./models/transformers/20240709_203536__oocl_120_step_950.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>orig_data_valid_loss</td><td>▄▇▄▂▂▂▂▂▂▂▂▁▁▁▁█▁▂▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/loss</td><td>█▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val/loss</td><td>▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▇▇▇▇▇▇▇▇▇▇▇█████████</td></tr><tr><td>valid_Df4/acc</td><td>▁▄▂▃▃▂▁▂▃▂▂▂▁▁▂▃▁▁▃▁▆██▇▇▇▆█▅▅▄▅▇▆▆▆▅▇██</td></tr><tr><td>valid_DfQ2/acc</td><td>▁▄▅▆▆▆▆▇▆▇▇▇▇▇▇█████▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇</td></tr><tr><td>valid_Dt3/acc</td><td>▇▃▁▄▄▃▃▅▃▂▂▂▁▁▁▁▂▂▂▂▇▃▆█▇▇▇▆▅▇▆▅▅▅▇▆▆█▇▇</td></tr><tr><td>valid_DtQ1/acc</td><td>▁▄▄▅▅▅▅▆▆▇▆▆▇▇▇▇▇▇█▇▇▇█▇█▇▇▇▇█▇▇█▇▇▇▇███</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>orig_data_valid_loss</td><td>0.00208</td></tr><tr><td>train/loss</td><td>0.08508</td></tr><tr><td>val/loss</td><td>12.10125</td></tr><tr><td>valid_Df4/acc</td><td>0.06667</td></tr><tr><td>valid_DfQ2/acc</td><td>0.47037</td></tr><tr><td>valid_Dt3/acc</td><td>0.07778</td></tr><tr><td>valid_DtQ1/acc</td><td>0.47037</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">seed=0</strong> at: <a href='https://wandb.ai/kilianovski/misha-iml/runs/38y5fc7o' target=\"_blank\">https://wandb.ai/kilianovski/misha-iml/runs/38y5fc7o</a><br/> View job at <a href='https://wandb.ai/kilianovski/misha-iml/jobs/QXJ0aWZhY3RDb2xsZWN0aW9uOjI0NzIwMzY4Mw==/version_details/v0' target=\"_blank\">https://wandb.ai/kilianovski/misha-iml/jobs/QXJ0aWZhY3RDb2xsZWN0aW9uOjI0NzIwMzY4Mw==/version_details/v0</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240709_203210-38y5fc7o/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moving model to device:  cpu\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a4c5be278fc497bb5d6fad5a6040c3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01113830879999619, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.4 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/mykhailokilianovskyi/src/aisc_oocl_experiments/wandb/run-20240709_203804-66h3z64b</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/kilianovski/misha-iml/runs/66h3z64b' target=\"_blank\">seed=1</a></strong> to <a href='https://wandb.ai/kilianovski/misha-iml' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/kilianovski/misha-iml' target=\"_blank\">https://wandb.ai/kilianovski/misha-iml</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/kilianovski/misha-iml/runs/66h3z64b' target=\"_blank\">https://wandb.ai/kilianovski/misha-iml/runs/66h3z64b</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "args.seed=1\n",
      "int_by_set\n",
      "{'DtQ1': [119, 81, 20, 90, 68, 41, 4, 79, 38, 10, 14, 95, 22, 78, 114, 71, 73, 52, 94, 9, 82, 116, 96, 93, 39, 36, 105, 50, 16, 33], 'DfQ2': [24, 6, 84, 5, 35, 74, 11, 104, 43, 112, 30, 66, 117, 25, 51, 31, 98, 59, 19, 64, 42, 65, 80, 113, 45, 61, 21, 47, 7, 18], 'Dt3': [99, 46, 88, 23, 103, 53, 86, 37, 58, 76, 118, 44, 91, 70, 111, 56, 28, 67, 85, 54, 27, 106, 1, 69, 107, 87, 2, 101, 40, 13], 'Df4': [75, 29, 92, 34, 109, 89, 0, 110, 77, 55, 49, 3, 62, 12, 26, 100, 48, 83, 60, 57, 115, 63, 15, 32, 8, 97, 102, 108, 72, 17]}\n",
      "DtQ1\n",
      "[119, 81, 20, 90, 68, 41, 4, 79, 38, 10, 14, 95, 22, 78, 114, 71, 73, 52, 94, 9, 82, 116, 96, 93, 39, 36, 105, 50, 16, 33]\n",
      "\n",
      "\n",
      "DfQ2\n",
      "[24, 6, 84, 5, 35, 74, 11, 104, 43, 112, 30, 66, 117, 25, 51, 31, 98, 59, 19, 64, 42, 65, 80, 113, 45, 61, 21, 47, 7, 18]\n",
      "\n",
      "\n",
      "Dt3\n",
      "[99, 46, 88, 23, 103, 53, 86, 37, 58, 76, 118, 44, 91, 70, 111, 56, 28, 67, 85, 54, 27, 106, 1, 69, 107, 87, 2, 101, 40, 13]\n",
      "\n",
      "\n",
      "Df4\n",
      "[75, 29, 92, 34, 109, 89, 0, 110, 77, 55, 49, 3, 62, 12, 26, 100, 48, 83, 60, 57, 115, 63, 15, 32, 8, 97, 102, 108, 72, 17]\n",
      "\n",
      "\n",
      "SAVING TO ./models/transformers/20240709_203811__data_oocl_120.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/pd/d5h1gjpx0lgc69qsrg7wv7x00000gp/T/ipykernel_6024/2477654783.py:270: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  result_tensor = torch.tensor(Z).view(N, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVING TO ./models/transformers/20240709_203952__oocl_120_step_500.pt\n",
      "SAVING TO ./models/transformers/20240709_204122__oocl_120_step_950.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>orig_data_valid_loss</td><td>▇█▃▃▂▂▂▂▂▂▂▁▂▂▂▁▁▁▁▁▁▄▁▂▂▁▁▁▂▁▁▁▁▁▁▁▁▁▂▁</td></tr><tr><td>train/loss</td><td>█▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val/loss</td><td>▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁████████████████████</td></tr><tr><td>valid_Df4/acc</td><td>▁▂▃▃▁▃▄▁▂▄▂▂▅▂▃▄▂▅▄▄▃▂▂▃▃▃▃▃▃▃▂▃▅▅▆▇▆█▇▆</td></tr><tr><td>valid_DfQ2/acc</td><td>▁▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇█▇██▇██▇▇██▇▇▇▇▇▇█▇██▇▇▇</td></tr><tr><td>valid_Dt3/acc</td><td>▁▂▅▃▆▆▅▆▅▄▃▄▇▅▆▅▆▆▆▇▇▄▄▃▄▅█▆█▆▇▆▆▃▅▅▂▂▂▃</td></tr><tr><td>valid_DtQ1/acc</td><td>▁▄▄▅▅▆▆▇▇▇▇▇█▇▇█▇███▇▇█▇▇███▇███████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>orig_data_valid_loss</td><td>0.00404</td></tr><tr><td>train/loss</td><td>0.07906</td></tr><tr><td>val/loss</td><td>13.63138</td></tr><tr><td>valid_Df4/acc</td><td>0.06944</td></tr><tr><td>valid_DfQ2/acc</td><td>0.48148</td></tr><tr><td>valid_Dt3/acc</td><td>0.03056</td></tr><tr><td>valid_DtQ1/acc</td><td>0.55185</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">seed=1</strong> at: <a href='https://wandb.ai/kilianovski/misha-iml/runs/66h3z64b' target=\"_blank\">https://wandb.ai/kilianovski/misha-iml/runs/66h3z64b</a><br/> View job at <a href='https://wandb.ai/kilianovski/misha-iml/jobs/QXJ0aWZhY3RDb2xsZWN0aW9uOjI0NzIwMzY4Mw==/version_details/v0' target=\"_blank\">https://wandb.ai/kilianovski/misha-iml/jobs/QXJ0aWZhY3RDb2xsZWN0aW9uOjI0NzIwMzY4Mw==/version_details/v0</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240709_203804-66h3z64b/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moving model to device:  cpu\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "130f999b42594d46a15ae9b3c3b76c03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011167702311104222, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.4 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/mykhailokilianovskyi/src/aisc_oocl_experiments/wandb/run-20240709_204409-3gli8e3n</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/kilianovski/misha-iml/runs/3gli8e3n' target=\"_blank\">seed=2</a></strong> to <a href='https://wandb.ai/kilianovski/misha-iml' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/kilianovski/misha-iml' target=\"_blank\">https://wandb.ai/kilianovski/misha-iml</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/kilianovski/misha-iml/runs/3gli8e3n' target=\"_blank\">https://wandb.ai/kilianovski/misha-iml/runs/3gli8e3n</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "args.seed=2\n",
      "int_by_set\n",
      "{'DtQ1': [117, 98, 8, 2, 38, 89, 12, 62, 76, 0, 5, 1, 60, 90, 109, 116, 51, 6, 91, 13, 18, 37, 118, 24, 105, 52, 16, 26, 68, 66], 'DfQ2': [9, 19, 78, 49, 86, 100, 14, 58, 44, 35, 36, 96, 43, 61, 42, 73, 99, 107, 97, 72, 31, 15, 33, 102, 104, 111, 63, 25, 84, 115], 'Dt3': [28, 83, 82, 45, 93, 53, 57, 23, 70, 101, 80, 95, 17, 75, 41, 79, 88, 29, 30, 22, 71, 112, 67, 54, 48, 40, 59, 114, 3, 119], 'Df4': [34, 64, 56, 69, 47, 65, 92, 50, 81, 55, 20, 87, 74, 4, 113, 27, 77, 32, 39, 85, 103, 94, 21, 106, 46, 10, 11, 7, 108, 110]}\n",
      "DtQ1\n",
      "[117, 98, 8, 2, 38, 89, 12, 62, 76, 0, 5, 1, 60, 90, 109, 116, 51, 6, 91, 13, 18, 37, 118, 24, 105, 52, 16, 26, 68, 66]\n",
      "\n",
      "\n",
      "DfQ2\n",
      "[9, 19, 78, 49, 86, 100, 14, 58, 44, 35, 36, 96, 43, 61, 42, 73, 99, 107, 97, 72, 31, 15, 33, 102, 104, 111, 63, 25, 84, 115]\n",
      "\n",
      "\n",
      "Dt3\n",
      "[28, 83, 82, 45, 93, 53, 57, 23, 70, 101, 80, 95, 17, 75, 41, 79, 88, 29, 30, 22, 71, 112, 67, 54, 48, 40, 59, 114, 3, 119]\n",
      "\n",
      "\n",
      "Df4\n",
      "[34, 64, 56, 69, 47, 65, 92, 50, 81, 55, 20, 87, 74, 4, 113, 27, 77, 32, 39, 85, 103, 94, 21, 106, 46, 10, 11, 7, 108, 110]\n",
      "\n",
      "\n",
      "SAVING TO ./models/transformers/20240709_204416__data_oocl_120.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/pd/d5h1gjpx0lgc69qsrg7wv7x00000gp/T/ipykernel_6024/2477654783.py:270: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  result_tensor = torch.tensor(Z).view(N, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVING TO ./models/transformers/20240709_204615__oocl_120_step_500.pt\n",
      "SAVING TO ./models/transformers/20240709_204800__oocl_120_step_950.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.023 MB uploaded\\r'), FloatProgress(value=0.04343596684148198, max=1.…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>orig_data_valid_loss</td><td>▅█▂▃▄▂▂▂▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/loss</td><td>█▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val/loss</td><td>▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▇▇▇▇▇█▇▇████████████</td></tr><tr><td>valid_Df4/acc</td><td>▆▂▅▅▃▅▁▄▄▄▄▃▃▄▃▂▄▁▃▂▇▇▆▆▇▇▇█▇▅▅▄▄▄▅▅▅▄▅▆</td></tr><tr><td>valid_DfQ2/acc</td><td>▁▅▅▆▆▆▇▆▇▇▇▇▇███▇███▇▇▇█▇▇▇████▇▇▇▇▇▇▇▇█</td></tr><tr><td>valid_Dt3/acc</td><td>▇▅▅▇▅▆▇▅▅▇▅▆▅▅▅▅▅▅▅▅▄▁▃▄▅█▂▂▄▅▅▇▆▇▄▅▄▅▅▅</td></tr><tr><td>valid_DtQ1/acc</td><td>▁▅▅▅▆▆▆▆▆▆▆▇▇▇▇██▇▇██▇█▇▇██▇███▇█▇▇█████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>orig_data_valid_loss</td><td>0.00086</td></tr><tr><td>train/loss</td><td>0.09395</td></tr><tr><td>val/loss</td><td>12.16662</td></tr><tr><td>valid_Df4/acc</td><td>0.04444</td></tr><tr><td>valid_DfQ2/acc</td><td>0.48889</td></tr><tr><td>valid_Dt3/acc</td><td>0.04167</td></tr><tr><td>valid_DtQ1/acc</td><td>0.45556</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">seed=2</strong> at: <a href='https://wandb.ai/kilianovski/misha-iml/runs/3gli8e3n' target=\"_blank\">https://wandb.ai/kilianovski/misha-iml/runs/3gli8e3n</a><br/> View job at <a href='https://wandb.ai/kilianovski/misha-iml/jobs/QXJ0aWZhY3RDb2xsZWN0aW9uOjI0NzIwMzY4Mw==/version_details/v0' target=\"_blank\">https://wandb.ai/kilianovski/misha-iml/jobs/QXJ0aWZhY3RDb2xsZWN0aW9uOjI0NzIwMzY4Mw==/version_details/v0</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240709_204409-3gli8e3n/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moving model to device:  cpu\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40ecb1c3219a44fe835939b8fea2facc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011168793522220869, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.4 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/mykhailokilianovskyi/src/aisc_oocl_experiments/wandb/run-20240709_205045-n4qh59b4</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/kilianovski/misha-iml/runs/n4qh59b4' target=\"_blank\">seed=3</a></strong> to <a href='https://wandb.ai/kilianovski/misha-iml' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/kilianovski/misha-iml' target=\"_blank\">https://wandb.ai/kilianovski/misha-iml</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/kilianovski/misha-iml/runs/n4qh59b4' target=\"_blank\">https://wandb.ai/kilianovski/misha-iml/runs/n4qh59b4</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "args.seed=3\n",
      "int_by_set\n",
      "{'DtQ1': [39, 83, 71, 93, 90, 51, 52, 116, 23, 35, 79, 28, 59, 84, 15, 86, 45, 98, 101, 109, 92, 57, 78, 9, 0, 65, 115, 31, 25, 11], 'DfQ2': [2, 61, 119, 99, 7, 18, 48, 40, 13, 6, 41, 58, 111, 87, 10, 44, 42, 67, 68, 88, 43, 21, 14, 64, 62, 37, 112, 22, 36, 102], 'Dt3': [53, 32, 26, 82, 55, 105, 27, 63, 72, 4, 12, 46, 17, 56, 73, 96, 54, 89, 76, 97, 34, 3, 38, 5, 118, 20, 110, 85, 108, 49], 'Df4': [66, 94, 95, 103, 19, 81, 50, 100, 104, 117, 106, 91, 24, 29, 70, 33, 113, 107, 1, 114, 8, 74, 80, 60, 77, 47, 16, 69, 75, 30]}\n",
      "DtQ1\n",
      "[39, 83, 71, 93, 90, 51, 52, 116, 23, 35, 79, 28, 59, 84, 15, 86, 45, 98, 101, 109, 92, 57, 78, 9, 0, 65, 115, 31, 25, 11]\n",
      "\n",
      "\n",
      "DfQ2\n",
      "[2, 61, 119, 99, 7, 18, 48, 40, 13, 6, 41, 58, 111, 87, 10, 44, 42, 67, 68, 88, 43, 21, 14, 64, 62, 37, 112, 22, 36, 102]\n",
      "\n",
      "\n",
      "Dt3\n",
      "[53, 32, 26, 82, 55, 105, 27, 63, 72, 4, 12, 46, 17, 56, 73, 96, 54, 89, 76, 97, 34, 3, 38, 5, 118, 20, 110, 85, 108, 49]\n",
      "\n",
      "\n",
      "Df4\n",
      "[66, 94, 95, 103, 19, 81, 50, 100, 104, 117, 106, 91, 24, 29, 70, 33, 113, 107, 1, 114, 8, 74, 80, 60, 77, 47, 16, 69, 75, 30]\n",
      "\n",
      "\n",
      "SAVING TO ./models/transformers/20240709_205051__data_oocl_120.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/pd/d5h1gjpx0lgc69qsrg7wv7x00000gp/T/ipykernel_6024/2477654783.py:270: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  result_tensor = torch.tensor(Z).view(N, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVING TO ./models/transformers/20240709_205248__oocl_120_step_500.pt\n",
      "SAVING TO ./models/transformers/20240709_205431__oocl_120_step_950.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d076e2afd0e94c61b7bcf98b03cad95d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.011 MB uploaded\\r'), FloatProgress(value=0.09172099669554346, max=1.…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>orig_data_valid_loss</td><td>▃█▃▃▂▃▁▂▂▁▂▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/loss</td><td>█▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val/loss</td><td>▃▂▂▂▂▂▂▂▁▂▁▁▁▁▁▁▁▁▁▁▇▇▇▇▇███████████████</td></tr><tr><td>valid_Df4/acc</td><td>▇▄▄▄▃▃▃▂▃▂▂▃▂▃▁▁▁▂▄▃▇▆▆▇▆▆▅▄▆█▇▅▆█▆▇▆▇▇▅</td></tr><tr><td>valid_DfQ2/acc</td><td>▁▆▆▆▆▇▇▇▇▇▇▇▇▇████████▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇</td></tr><tr><td>valid_Dt3/acc</td><td>▂▆▄▃▄▆▆▄▆▅▇▆▇▃▇▆▇█▆▆▄▄▂▄▄▁▃▁▂▂▂▃▄▃▄▄▃▄▄▄</td></tr><tr><td>valid_DtQ1/acc</td><td>▁▅▅▆▆▇▇▇▇▇▇▇▇▇▇▇████▇▇███▇▇▇▇▇█▇▇█▇█▇█▇█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>orig_data_valid_loss</td><td>0.00158</td></tr><tr><td>train/loss</td><td>0.08932</td></tr><tr><td>val/loss</td><td>12.18048</td></tr><tr><td>valid_Df4/acc</td><td>0.04722</td></tr><tr><td>valid_DfQ2/acc</td><td>0.3963</td></tr><tr><td>valid_Dt3/acc</td><td>0.04722</td></tr><tr><td>valid_DtQ1/acc</td><td>0.51111</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">seed=3</strong> at: <a href='https://wandb.ai/kilianovski/misha-iml/runs/n4qh59b4' target=\"_blank\">https://wandb.ai/kilianovski/misha-iml/runs/n4qh59b4</a><br/> View job at <a href='https://wandb.ai/kilianovski/misha-iml/jobs/QXJ0aWZhY3RDb2xsZWN0aW9uOjI0NzIwMzY4Mw==/version_details/v0' target=\"_blank\">https://wandb.ai/kilianovski/misha-iml/jobs/QXJ0aWZhY3RDb2xsZWN0aW9uOjI0NzIwMzY4Mw==/version_details/v0</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240709_205045-n4qh59b4/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moving model to device:  cpu\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1542771f95e54652a7f00d78bcc0a29f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01114898657777101, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.4 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/mykhailokilianovskyi/src/aisc_oocl_experiments/wandb/run-20240709_205715-f0va7yi3</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/kilianovski/misha-iml/runs/f0va7yi3' target=\"_blank\">seed=4</a></strong> to <a href='https://wandb.ai/kilianovski/misha-iml' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/kilianovski/misha-iml' target=\"_blank\">https://wandb.ai/kilianovski/misha-iml</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/kilianovski/misha-iml/runs/f0va7yi3' target=\"_blank\">https://wandb.ai/kilianovski/misha-iml/runs/f0va7yi3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "args.seed=4\n",
      "int_by_set\n",
      "{'DtQ1': [48, 25, 45, 83, 32, 6, 53, 73, 58, 105, 85, 72, 86, 23, 15, 71, 76, 93, 101, 114, 100, 57, 59, 18, 67, 111, 104, 75, 1, 56], 'DfQ2': [94, 81, 69, 20, 95, 78, 74, 115, 62, 42, 26, 4, 12, 9, 89, 44, 119, 41, 91, 116, 17, 40, 29, 63, 5, 110, 109, 106, 16, 113], 'Dt3': [14, 10, 103, 55, 36, 54, 52, 90, 65, 88, 87, 0, 118, 108, 84, 99, 60, 79, 98, 31, 64, 49, 43, 77, 112, 47, 80, 107, 39, 21], 'Df4': [24, 34, 96, 82, 3, 27, 33, 117, 22, 35, 46, 68, 66, 28, 7, 97, 102, 37, 70, 51, 2, 8, 11, 19, 61, 50, 92, 13, 38, 30]}\n",
      "DtQ1\n",
      "[48, 25, 45, 83, 32, 6, 53, 73, 58, 105, 85, 72, 86, 23, 15, 71, 76, 93, 101, 114, 100, 57, 59, 18, 67, 111, 104, 75, 1, 56]\n",
      "\n",
      "\n",
      "DfQ2\n",
      "[94, 81, 69, 20, 95, 78, 74, 115, 62, 42, 26, 4, 12, 9, 89, 44, 119, 41, 91, 116, 17, 40, 29, 63, 5, 110, 109, 106, 16, 113]\n",
      "\n",
      "\n",
      "Dt3\n",
      "[14, 10, 103, 55, 36, 54, 52, 90, 65, 88, 87, 0, 118, 108, 84, 99, 60, 79, 98, 31, 64, 49, 43, 77, 112, 47, 80, 107, 39, 21]\n",
      "\n",
      "\n",
      "Df4\n",
      "[24, 34, 96, 82, 3, 27, 33, 117, 22, 35, 46, 68, 66, 28, 7, 97, 102, 37, 70, 51, 2, 8, 11, 19, 61, 50, 92, 13, 38, 30]\n",
      "\n",
      "\n",
      "SAVING TO ./models/transformers/20240709_205722__data_oocl_120.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/pd/d5h1gjpx0lgc69qsrg7wv7x00000gp/T/ipykernel_6024/2477654783.py:270: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  result_tensor = torch.tensor(Z).view(N, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVING TO ./models/transformers/20240709_205914__oocl_120_step_500.pt\n",
      "SAVING TO ./models/transformers/20240709_210055__oocl_120_step_950.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a90dd5da38854041a566c8bee77375b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>orig_data_valid_loss</td><td>▃█▃▂▂▂▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/loss</td><td>█▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val/loss</td><td>▃▃▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁██████████████████▇▇</td></tr><tr><td>valid_Df4/acc</td><td>▁▂▂▂▂▃▃▂▃▃▆▄▄▄▄▅▆▄▆▅▄▄▄▆▅▆▇▅█▇▆▆▅▆█▅▇▆██</td></tr><tr><td>valid_DfQ2/acc</td><td>▁▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇█████▇█▇█▇▇▇▇▇▇█</td></tr><tr><td>valid_Dt3/acc</td><td>▆▅▂▂▂▂▃▁▄▂▃▃▃▅▄▃▄▄▄▄▅▃▄▅▄▄▄▃▃▂▅▅▅▆▇▅▅▇██</td></tr><tr><td>valid_DtQ1/acc</td><td>▁▅▅▅▆▆▆▇▆▇▇▇▇▇▇▇█▇█▇█▇▇▇█████▇█▇▇▇▇▇▇▇██</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>orig_data_valid_loss</td><td>0.00175</td></tr><tr><td>train/loss</td><td>0.08164</td></tr><tr><td>val/loss</td><td>12.25665</td></tr><tr><td>valid_Df4/acc</td><td>0.075</td></tr><tr><td>valid_DfQ2/acc</td><td>0.47407</td></tr><tr><td>valid_Dt3/acc</td><td>0.06111</td></tr><tr><td>valid_DtQ1/acc</td><td>0.47037</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">seed=4</strong> at: <a href='https://wandb.ai/kilianovski/misha-iml/runs/f0va7yi3' target=\"_blank\">https://wandb.ai/kilianovski/misha-iml/runs/f0va7yi3</a><br/> View job at <a href='https://wandb.ai/kilianovski/misha-iml/jobs/QXJ0aWZhY3RDb2xsZWN0aW9uOjI0NzIwMzY4Mw==/version_details/v0' target=\"_blank\">https://wandb.ai/kilianovski/misha-iml/jobs/QXJ0aWZhY3RDb2xsZWN0aW9uOjI0NzIwMzY4Mw==/version_details/v0</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240709_205715-f0va7yi3/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moving model to device:  cpu\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9eba057f525b4bd58168716a7806b2db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011167702777776059, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.4 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/mykhailokilianovskyi/src/aisc_oocl_experiments/wandb/run-20240709_210342-wu6zq4wi</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/kilianovski/misha-iml/runs/wu6zq4wi' target=\"_blank\">seed=5</a></strong> to <a href='https://wandb.ai/kilianovski/misha-iml' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/kilianovski/misha-iml' target=\"_blank\">https://wandb.ai/kilianovski/misha-iml</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/kilianovski/misha-iml/runs/wu6zq4wi' target=\"_blank\">https://wandb.ai/kilianovski/misha-iml/runs/wu6zq4wi</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "args.seed=5\n",
      "int_by_set\n",
      "{'DtQ1': [61, 58, 106, 29, 62, 63, 24, 28, 46, 34, 100, 75, 15, 8, 71, 118, 7, 89, 103, 42, 5, 33, 115, 51, 18, 12, 36, 95, 93, 84], 'DfQ2': [50, 66, 97, 92, 57, 109, 39, 65, 41, 11, 86, 30, 44, 22, 54, 81, 55, 116, 43, 53, 77, 72, 64, 90, 19, 112, 4, 82, 85, 108], 'Dt3': [10, 68, 110, 2, 38, 87, 70, 114, 76, 96, 25, 40, 37, 74, 21, 91, 26, 78, 0, 80, 16, 56, 104, 119, 17, 9, 102, 49, 23, 35], 'Df4': [52, 27, 1, 98, 73, 13, 69, 48, 105, 60, 47, 14, 20, 6, 111, 31, 99, 59, 113, 3, 67, 83, 117, 107, 88, 101, 45, 94, 32, 79]}\n",
      "DtQ1\n",
      "[61, 58, 106, 29, 62, 63, 24, 28, 46, 34, 100, 75, 15, 8, 71, 118, 7, 89, 103, 42, 5, 33, 115, 51, 18, 12, 36, 95, 93, 84]\n",
      "\n",
      "\n",
      "DfQ2\n",
      "[50, 66, 97, 92, 57, 109, 39, 65, 41, 11, 86, 30, 44, 22, 54, 81, 55, 116, 43, 53, 77, 72, 64, 90, 19, 112, 4, 82, 85, 108]\n",
      "\n",
      "\n",
      "Dt3\n",
      "[10, 68, 110, 2, 38, 87, 70, 114, 76, 96, 25, 40, 37, 74, 21, 91, 26, 78, 0, 80, 16, 56, 104, 119, 17, 9, 102, 49, 23, 35]\n",
      "\n",
      "\n",
      "Df4\n",
      "[52, 27, 1, 98, 73, 13, 69, 48, 105, 60, 47, 14, 20, 6, 111, 31, 99, 59, 113, 3, 67, 83, 117, 107, 88, 101, 45, 94, 32, 79]\n",
      "\n",
      "\n",
      "SAVING TO ./models/transformers/20240709_210349__data_oocl_120.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/pd/d5h1gjpx0lgc69qsrg7wv7x00000gp/T/ipykernel_6024/2477654783.py:270: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  result_tensor = torch.tensor(Z).view(N, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVING TO ./models/transformers/20240709_210537__oocl_120_step_500.pt\n",
      "SAVING TO ./models/transformers/20240709_210715__oocl_120_step_950.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5d48299479e48f29582348c832eb262",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>orig_data_valid_loss</td><td>▄█▇▅▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁</td></tr><tr><td>train/loss</td><td>█▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val/loss</td><td>▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▇▇▇▇████████████████</td></tr><tr><td>valid_Df4/acc</td><td>▄▆▃▆▄▄▂▂▃▄▅▄▄▃▄▁▂▂▄▂█▃▂▅▅▃▄▄▅▆▃▄▄▄▂▂▂▁▃▃</td></tr><tr><td>valid_DfQ2/acc</td><td>▁▅▆▆▆▇▇▇▇▇██████▇███▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇</td></tr><tr><td>valid_Dt3/acc</td><td>▄▅▆▅▅▃▂▄▄▃▇▂▄▂▄▃▄▁▂▅▇▇▇▆▇█▇▇▇▄▆▆▇█▇█▄▅▆▅</td></tr><tr><td>valid_DtQ1/acc</td><td>▁▄▅▅▆▆▇▆▇▇▆▇▇▇▇▇█████▇▇█▇▇▇▇▇▇▇▇█▇▇▇▇█▇█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>orig_data_valid_loss</td><td>0.00195</td></tr><tr><td>train/loss</td><td>0.08914</td></tr><tr><td>val/loss</td><td>12.82408</td></tr><tr><td>valid_Df4/acc</td><td>0.04722</td></tr><tr><td>valid_DfQ2/acc</td><td>0.45556</td></tr><tr><td>valid_Dt3/acc</td><td>0.06389</td></tr><tr><td>valid_DtQ1/acc</td><td>0.45556</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">seed=5</strong> at: <a href='https://wandb.ai/kilianovski/misha-iml/runs/wu6zq4wi' target=\"_blank\">https://wandb.ai/kilianovski/misha-iml/runs/wu6zq4wi</a><br/> View job at <a href='https://wandb.ai/kilianovski/misha-iml/jobs/QXJ0aWZhY3RDb2xsZWN0aW9uOjI0NzIwMzY4Mw==/version_details/v0' target=\"_blank\">https://wandb.ai/kilianovski/misha-iml/jobs/QXJ0aWZhY3RDb2xsZWN0aW9uOjI0NzIwMzY4Mw==/version_details/v0</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240709_210342-wu6zq4wi/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for seed in SEEDS:\n",
    "    train_oocl_stage_1_2(args, seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "456b8775-b325-439a-b70b-80ddf8e5ada0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moving model to device:  cpu\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94298e4be1fd41f8ad384ce6aaa1ed5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011144811566676556, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.4 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/mykhailokilianovskyi/src/aisc_oocl_experiments/wandb/run-20240709_210954-ojg3t7nh</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/kilianovski/misha-iml/runs/ojg3t7nh' target=\"_blank\">seed=9</a></strong> to <a href='https://wandb.ai/kilianovski/misha-iml' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/kilianovski/misha-iml' target=\"_blank\">https://wandb.ai/kilianovski/misha-iml</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/kilianovski/misha-iml/runs/ojg3t7nh' target=\"_blank\">https://wandb.ai/kilianovski/misha-iml/runs/ojg3t7nh</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "args.seed=9\n",
      "int_by_set\n",
      "{'DtQ1': [22, 102, 97, 100, 41, 105, 84, 83, 15, 96, 33, 24, 106, 80, 44, 66, 88, 40, 55, 74, 87, 63, 18, 29, 114, 79, 19, 112, 65, 61], 'DfQ2': [45, 2, 103, 9, 73, 39, 71, 4, 76, 51, 46, 31, 36, 108, 32, 1, 107, 85, 72, 56, 95, 69, 12, 82, 67, 60, 104, 38, 68, 94], 'Dt3': [58, 117, 27, 91, 3, 115, 62, 99, 7, 52, 111, 25, 101, 113, 35, 50, 81, 116, 11, 53, 28, 26, 37, 13, 49, 8, 75, 109, 16, 14], 'Df4': [6, 30, 98, 20, 54, 92, 57, 90, 21, 48, 93, 5, 89, 118, 70, 42, 10, 77, 119, 64, 43, 0, 86, 110, 23, 17, 34, 47, 78, 59]}\n",
      "DtQ1\n",
      "[22, 102, 97, 100, 41, 105, 84, 83, 15, 96, 33, 24, 106, 80, 44, 66, 88, 40, 55, 74, 87, 63, 18, 29, 114, 79, 19, 112, 65, 61]\n",
      "\n",
      "\n",
      "DfQ2\n",
      "[45, 2, 103, 9, 73, 39, 71, 4, 76, 51, 46, 31, 36, 108, 32, 1, 107, 85, 72, 56, 95, 69, 12, 82, 67, 60, 104, 38, 68, 94]\n",
      "\n",
      "\n",
      "Dt3\n",
      "[58, 117, 27, 91, 3, 115, 62, 99, 7, 52, 111, 25, 101, 113, 35, 50, 81, 116, 11, 53, 28, 26, 37, 13, 49, 8, 75, 109, 16, 14]\n",
      "\n",
      "\n",
      "Df4\n",
      "[6, 30, 98, 20, 54, 92, 57, 90, 21, 48, 93, 5, 89, 118, 70, 42, 10, 77, 119, 64, 43, 0, 86, 110, 23, 17, 34, 47, 78, 59]\n",
      "\n",
      "\n",
      "SAVING TO ./models/transformers/20240709_211001__data_oocl_120.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/pd/d5h1gjpx0lgc69qsrg7wv7x00000gp/T/ipykernel_6024/2477654783.py:270: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  result_tensor = torch.tensor(Z).view(N, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVING TO ./models/transformers/20240709_211145__oocl_120_step_500.pt\n",
      "SAVING TO ./models/transformers/20240709_211326__oocl_120_step_950.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>orig_data_valid_loss</td><td>▆█▇▅▄▄▆▅▅▄▂▂▁▂▁▂▁▄▃▂▂▁▂▂▁▂▁▁▁▂▁▁▂▁▂▁▁▁▁▂</td></tr><tr><td>train/loss</td><td>█▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val/loss</td><td>▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁████████████████████</td></tr><tr><td>valid_Df4/acc</td><td>▁▄▂▁▁▃▂▃▃▂▄▃▄▄▄▂▃▂▂▅▄▃▂▄▆▇▆▇▇▇▆▆▅▆█▇▆▅▆▆</td></tr><tr><td>valid_DfQ2/acc</td><td>▁▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▆▆▆▇▇▇▇▇▇▇▇▇▇▇██▇█▇▇</td></tr><tr><td>valid_Dt3/acc</td><td>▄▃▄▄▃▂▃▃▄▂▂▅▂▁▄▃▂▄▃▅▄▄▄▂▂▄▄▄▃▄▇▅▆▄▄▅▅▆█▆</td></tr><tr><td>valid_DtQ1/acc</td><td>▁▅▆▆▆▇▇▇▇▇▇█████████▇▇▇▇▇▇▇▇▇███▇▇▇██▇██</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>orig_data_valid_loss</td><td>0.0025</td></tr><tr><td>train/loss</td><td>0.0875</td></tr><tr><td>val/loss</td><td>12.51795</td></tr><tr><td>valid_Df4/acc</td><td>0.07222</td></tr><tr><td>valid_DfQ2/acc</td><td>0.40741</td></tr><tr><td>valid_Dt3/acc</td><td>0.05556</td></tr><tr><td>valid_DtQ1/acc</td><td>0.45185</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">seed=9</strong> at: <a href='https://wandb.ai/kilianovski/misha-iml/runs/ojg3t7nh' target=\"_blank\">https://wandb.ai/kilianovski/misha-iml/runs/ojg3t7nh</a><br/> View job at <a href='https://wandb.ai/kilianovski/misha-iml/jobs/QXJ0aWZhY3RDb2xsZWN0aW9uOjI0NzIwMzY4Mw==/version_details/v0' target=\"_blank\">https://wandb.ai/kilianovski/misha-iml/jobs/QXJ0aWZhY3RDb2xsZWN0aW9uOjI0NzIwMzY4Mw==/version_details/v0</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240709_210954-ojg3t7nh/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moving model to device:  cpu\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe21297635f04313b64f32194364cb94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011112717133336345, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.4 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/mykhailokilianovskyi/src/aisc_oocl_experiments/wandb/run-20240709_211614-wk2r8bhp</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/kilianovski/misha-iml/runs/wk2r8bhp' target=\"_blank\">seed=10</a></strong> to <a href='https://wandb.ai/kilianovski/misha-iml' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/kilianovski/misha-iml' target=\"_blank\">https://wandb.ai/kilianovski/misha-iml</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/kilianovski/misha-iml/runs/wk2r8bhp' target=\"_blank\">https://wandb.ai/kilianovski/misha-iml/runs/wk2r8bhp</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "args.seed=10\n",
      "int_by_set\n",
      "{'DtQ1': [39, 72, 114, 29, 18, 87, 116, 75, 112, 108, 11, 52, 27, 50, 65, 49, 64, 63, 44, 25, 3, 43, 16, 93, 92, 8, 21, 106, 81, 67], 'DfQ2': [13, 85, 12, 79, 28, 6, 7, 69, 47, 23, 89, 71, 100, 76, 34, 102, 42, 70, 19, 99, 51, 2, 15, 113, 14, 90, 10, 32, 117, 109], 'Dt3': [37, 101, 111, 60, 55, 57, 40, 115, 107, 68, 84, 24, 82, 80, 0, 74, 96, 91, 78, 56, 30, 88, 94, 97, 38, 22, 58, 33, 86, 36], 'Df4': [98, 48, 45, 77, 17, 53, 5, 46, 95, 31, 9, 41, 110, 66, 118, 20, 103, 83, 35, 105, 62, 104, 59, 26, 1, 119, 61, 54, 4, 73]}\n",
      "DtQ1\n",
      "[39, 72, 114, 29, 18, 87, 116, 75, 112, 108, 11, 52, 27, 50, 65, 49, 64, 63, 44, 25, 3, 43, 16, 93, 92, 8, 21, 106, 81, 67]\n",
      "\n",
      "\n",
      "DfQ2\n",
      "[13, 85, 12, 79, 28, 6, 7, 69, 47, 23, 89, 71, 100, 76, 34, 102, 42, 70, 19, 99, 51, 2, 15, 113, 14, 90, 10, 32, 117, 109]\n",
      "\n",
      "\n",
      "Dt3\n",
      "[37, 101, 111, 60, 55, 57, 40, 115, 107, 68, 84, 24, 82, 80, 0, 74, 96, 91, 78, 56, 30, 88, 94, 97, 38, 22, 58, 33, 86, 36]\n",
      "\n",
      "\n",
      "Df4\n",
      "[98, 48, 45, 77, 17, 53, 5, 46, 95, 31, 9, 41, 110, 66, 118, 20, 103, 83, 35, 105, 62, 104, 59, 26, 1, 119, 61, 54, 4, 73]\n",
      "\n",
      "\n",
      "SAVING TO ./models/transformers/20240709_211620__data_oocl_120.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/pd/d5h1gjpx0lgc69qsrg7wv7x00000gp/T/ipykernel_6024/2477654783.py:270: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  result_tensor = torch.tensor(Z).view(N, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVING TO ./models/transformers/20240709_211820__oocl_120_step_500.pt\n",
      "SAVING TO ./models/transformers/20240709_212006__oocl_120_step_950.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>orig_data_valid_loss</td><td>▂█▇▇▄▃▂▂▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁</td></tr><tr><td>train/loss</td><td>█▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val/loss</td><td>▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁████████████████████</td></tr><tr><td>valid_Df4/acc</td><td>▁▅▄▅▅▆▄▄▃▄▄▃▅▆▄▇█▆▇▇▆▄▄▅▄▃▅▃▆▆▇▄▇▅▆▄▆▆▄▃</td></tr><tr><td>valid_DfQ2/acc</td><td>▁▅▆▆▇▇█████▇████████▇▇▇▇▇███████▇███████</td></tr><tr><td>valid_Dt3/acc</td><td>▅▄▃▁▄▄▂▅▄▄▅▅▆▅▆▄▄▅▅█▄▄▄▄▇▆▄█▇▆▆▇▇▇▄▇▅█▆▆</td></tr><tr><td>valid_DtQ1/acc</td><td>▁▄▄▅▆▅▆▆▇▇▇▆▇▇▇▇▇▇██▇▇██▇▇███████▇▇▇▇███</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>orig_data_valid_loss</td><td>0.00115</td></tr><tr><td>train/loss</td><td>0.08598</td></tr><tr><td>val/loss</td><td>12.48827</td></tr><tr><td>valid_Df4/acc</td><td>0.05556</td></tr><tr><td>valid_DfQ2/acc</td><td>0.46296</td></tr><tr><td>valid_Dt3/acc</td><td>0.02778</td></tr><tr><td>valid_DtQ1/acc</td><td>0.47037</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">seed=10</strong> at: <a href='https://wandb.ai/kilianovski/misha-iml/runs/wk2r8bhp' target=\"_blank\">https://wandb.ai/kilianovski/misha-iml/runs/wk2r8bhp</a><br/> View job at <a href='https://wandb.ai/kilianovski/misha-iml/jobs/QXJ0aWZhY3RDb2xsZWN0aW9uOjI0NzIwMzY4Mw==/version_details/v0' target=\"_blank\">https://wandb.ai/kilianovski/misha-iml/jobs/QXJ0aWZhY3RDb2xsZWN0aW9uOjI0NzIwMzY4Mw==/version_details/v0</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240709_211614-wk2r8bhp/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moving model to device:  cpu\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63df2fbf99f04d849c43d77073f95a0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01116877222221875, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.4 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/mykhailokilianovskyi/src/aisc_oocl_experiments/wandb/run-20240709_212256-rfogfcjg</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/kilianovski/misha-iml/runs/rfogfcjg' target=\"_blank\">seed=11</a></strong> to <a href='https://wandb.ai/kilianovski/misha-iml' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/kilianovski/misha-iml' target=\"_blank\">https://wandb.ai/kilianovski/misha-iml</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/kilianovski/misha-iml/runs/rfogfcjg' target=\"_blank\">https://wandb.ai/kilianovski/misha-iml/runs/rfogfcjg</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "args.seed=11\n",
      "int_by_set\n",
      "{'DtQ1': [15, 89, 17, 55, 96, 72, 64, 34, 22, 44, 28, 54, 33, 19, 31, 105, 73, 107, 69, 104, 52, 95, 98, 40, 27, 9, 2, 106, 93, 21], 'DfQ2': [61, 100, 42, 62, 46, 43, 77, 118, 39, 13, 70, 90, 49, 87, 51, 47, 117, 6, 36, 84, 86, 97, 32, 14, 48, 85, 16, 45, 92, 53], 'Dt3': [74, 82, 26, 35, 58, 10, 0, 63, 37, 29, 66, 25, 56, 41, 114, 3, 91, 30, 111, 4, 7, 8, 67, 1, 79, 20, 94, 103, 83, 115], 'Df4': [50, 76, 5, 81, 88, 68, 11, 18, 38, 113, 12, 108, 101, 78, 80, 60, 112, 102, 23, 24, 75, 116, 65, 119, 59, 99, 109, 71, 110, 57]}\n",
      "DtQ1\n",
      "[15, 89, 17, 55, 96, 72, 64, 34, 22, 44, 28, 54, 33, 19, 31, 105, 73, 107, 69, 104, 52, 95, 98, 40, 27, 9, 2, 106, 93, 21]\n",
      "\n",
      "\n",
      "DfQ2\n",
      "[61, 100, 42, 62, 46, 43, 77, 118, 39, 13, 70, 90, 49, 87, 51, 47, 117, 6, 36, 84, 86, 97, 32, 14, 48, 85, 16, 45, 92, 53]\n",
      "\n",
      "\n",
      "Dt3\n",
      "[74, 82, 26, 35, 58, 10, 0, 63, 37, 29, 66, 25, 56, 41, 114, 3, 91, 30, 111, 4, 7, 8, 67, 1, 79, 20, 94, 103, 83, 115]\n",
      "\n",
      "\n",
      "Df4\n",
      "[50, 76, 5, 81, 88, 68, 11, 18, 38, 113, 12, 108, 101, 78, 80, 60, 112, 102, 23, 24, 75, 116, 65, 119, 59, 99, 109, 71, 110, 57]\n",
      "\n",
      "\n",
      "SAVING TO ./models/transformers/20240709_212303__data_oocl_120.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/pd/d5h1gjpx0lgc69qsrg7wv7x00000gp/T/ipykernel_6024/2477654783.py:270: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  result_tensor = torch.tensor(Z).view(N, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVING TO ./models/transformers/20240709_212451__oocl_120_step_500.pt\n",
      "SAVING TO ./models/transformers/20240709_212635__oocl_120_step_950.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>orig_data_valid_loss</td><td>▄▆▂▂▂▁▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▂▂██▁▂▁▂▁▁▁▁▁▁</td></tr><tr><td>train/loss</td><td>█▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val/loss</td><td>▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁████████████████████</td></tr><tr><td>valid_Df4/acc</td><td>▁▃▁▂▄▅▄▄▂▃▄▂▃▂▁▂▄▂▁▃▇▆▇▇▇██▆▇▄▅▆▅▇▇▆▇███</td></tr><tr><td>valid_DfQ2/acc</td><td>▁▅▅▅▆▆▆▆▇▇▇▇▇▇▇▇▇███▇█▇██▇██████▇█▇▇██▇▇</td></tr><tr><td>valid_Dt3/acc</td><td>▆█▆▄▅▄▅▆▆▅▅█▂▆▅▅▄▃▃▁▄▂▃▃▃▂▄▃▃▅▅▃▆▆▅▅▅▆▆▃</td></tr><tr><td>valid_DtQ1/acc</td><td>▁▅▅▅▆▆▆▆▇▇▇▇█████████▇█▇▇████▇█▇██▇████▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>orig_data_valid_loss</td><td>0.00141</td></tr><tr><td>train/loss</td><td>0.08431</td></tr><tr><td>val/loss</td><td>12.92606</td></tr><tr><td>valid_Df4/acc</td><td>0.07222</td></tr><tr><td>valid_DfQ2/acc</td><td>0.35556</td></tr><tr><td>valid_Dt3/acc</td><td>0.03611</td></tr><tr><td>valid_DtQ1/acc</td><td>0.43333</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">seed=11</strong> at: <a href='https://wandb.ai/kilianovski/misha-iml/runs/rfogfcjg' target=\"_blank\">https://wandb.ai/kilianovski/misha-iml/runs/rfogfcjg</a><br/> View job at <a href='https://wandb.ai/kilianovski/misha-iml/jobs/QXJ0aWZhY3RDb2xsZWN0aW9uOjI0NzIwMzY4Mw==/version_details/v0' target=\"_blank\">https://wandb.ai/kilianovski/misha-iml/jobs/QXJ0aWZhY3RDb2xsZWN0aW9uOjI0NzIwMzY4Mw==/version_details/v0</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240709_212256-rfogfcjg/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moving model to device:  cpu\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "971b0b736f8949389f8e84e5485a1e0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011167385188895828, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.4 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/mykhailokilianovskyi/src/aisc_oocl_experiments/wandb/run-20240709_212932-8pbpc6tv</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/kilianovski/misha-iml/runs/8pbpc6tv' target=\"_blank\">seed=12</a></strong> to <a href='https://wandb.ai/kilianovski/misha-iml' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/kilianovski/misha-iml' target=\"_blank\">https://wandb.ai/kilianovski/misha-iml</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/kilianovski/misha-iml/runs/8pbpc6tv' target=\"_blank\">https://wandb.ai/kilianovski/misha-iml/runs/8pbpc6tv</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "args.seed=12\n",
      "int_by_set\n",
      "{'DtQ1': [66, 37, 108, 92, 106, 52, 70, 33, 62, 102, 104, 97, 116, 4, 39, 89, 8, 31, 55, 80, 74, 3, 45, 90, 75, 59, 13, 57, 112, 100], 'DfQ2': [77, 83, 27, 95, 105, 98, 109, 36, 32, 72, 49, 68, 15, 81, 107, 19, 86, 63, 114, 23, 22, 16, 42, 50, 12, 5, 46, 41, 111, 118], 'Dt3': [24, 38, 30, 119, 53, 115, 10, 64, 21, 6, 94, 101, 40, 69, 17, 78, 14, 96, 54, 99, 28, 87, 91, 2, 11, 51, 93, 65, 9, 25], 'Df4': [73, 7, 26, 43, 20, 110, 56, 113, 79, 117, 0, 71, 29, 76, 88, 58, 103, 82, 35, 61, 47, 1, 48, 18, 44, 85, 67, 84, 34, 60]}\n",
      "DtQ1\n",
      "[66, 37, 108, 92, 106, 52, 70, 33, 62, 102, 104, 97, 116, 4, 39, 89, 8, 31, 55, 80, 74, 3, 45, 90, 75, 59, 13, 57, 112, 100]\n",
      "\n",
      "\n",
      "DfQ2\n",
      "[77, 83, 27, 95, 105, 98, 109, 36, 32, 72, 49, 68, 15, 81, 107, 19, 86, 63, 114, 23, 22, 16, 42, 50, 12, 5, 46, 41, 111, 118]\n",
      "\n",
      "\n",
      "Dt3\n",
      "[24, 38, 30, 119, 53, 115, 10, 64, 21, 6, 94, 101, 40, 69, 17, 78, 14, 96, 54, 99, 28, 87, 91, 2, 11, 51, 93, 65, 9, 25]\n",
      "\n",
      "\n",
      "Df4\n",
      "[73, 7, 26, 43, 20, 110, 56, 113, 79, 117, 0, 71, 29, 76, 88, 58, 103, 82, 35, 61, 47, 1, 48, 18, 44, 85, 67, 84, 34, 60]\n",
      "\n",
      "\n",
      "SAVING TO ./models/transformers/20240709_212939__data_oocl_120.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/pd/d5h1gjpx0lgc69qsrg7wv7x00000gp/T/ipykernel_6024/2477654783.py:270: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  result_tensor = torch.tensor(Z).view(N, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVING TO ./models/transformers/20240709_213144__oocl_120_step_500.pt\n",
      "SAVING TO ./models/transformers/20240709_213324__oocl_120_step_950.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8756f11fc1054601916400699a242dda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>orig_data_valid_loss</td><td>▂█▃▅▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/loss</td><td>█▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val/loss</td><td>▃▂▂▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▇▇▇▇▇▇█▇████████████</td></tr><tr><td>valid_Df4/acc</td><td>▇▄▃▅▂▃▂▂▁▂▃▄▄▂▁▃▂▂▂▂█▆▆▂▄▃▃▂▂▂▂▃▂▃▃▂▄▄▅▆</td></tr><tr><td>valid_DfQ2/acc</td><td>▁▅▅▆▆▆▆▇▇▇▇▇█████▇█▇▇▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇</td></tr><tr><td>valid_Dt3/acc</td><td>▅▄▄▄▅▄▄█▆▅▅▇▆▄▅▇▅▆▇▆▆▂▂▃▅▄▄▅▅▅▃▄▄▅▂▂▂▃▁▂</td></tr><tr><td>valid_DtQ1/acc</td><td>▁▅▅▆▆▆▆▇▇▇▇▇▇███████▇▇▇▇▇▇▇▇▇██▇▇█▇▇▇▇▇▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>orig_data_valid_loss</td><td>0.00124</td></tr><tr><td>train/loss</td><td>0.09408</td></tr><tr><td>val/loss</td><td>12.45841</td></tr><tr><td>valid_Df4/acc</td><td>0.06667</td></tr><tr><td>valid_DfQ2/acc</td><td>0.44074</td></tr><tr><td>valid_Dt3/acc</td><td>0.025</td></tr><tr><td>valid_DtQ1/acc</td><td>0.51111</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">seed=12</strong> at: <a href='https://wandb.ai/kilianovski/misha-iml/runs/8pbpc6tv' target=\"_blank\">https://wandb.ai/kilianovski/misha-iml/runs/8pbpc6tv</a><br/> View job at <a href='https://wandb.ai/kilianovski/misha-iml/jobs/QXJ0aWZhY3RDb2xsZWN0aW9uOjI0NzIwMzY4Mw==/version_details/v0' target=\"_blank\">https://wandb.ai/kilianovski/misha-iml/jobs/QXJ0aWZhY3RDb2xsZWN0aW9uOjI0NzIwMzY4Mw==/version_details/v0</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240709_212932-8pbpc6tv/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for seed in [9,10,11,12]:\n",
    "    train_oocl_stage_1_2(args, seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfca2920-4d58-4a07-900b-02915c323070",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
